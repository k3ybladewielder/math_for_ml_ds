{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4624802",
   "metadata": {},
   "source": [
    "# Álgebra Linear e Otimização para Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce507d",
   "metadata": {},
   "source": [
    "Notas e resumos do estudo sobre álgebra linear e otimização focado em machine learning, baseado no livro \n",
    "_[Linear Algebra and Optimization for Machine Learning](https://doi.org/10.1007/978-3-030-40344-7)_ de Charu C. Aggarwal. Para facilitar a localização das notas, estou utilizando o sumário do livro nos tópicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6169406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T22:44:04.903649Z",
     "start_time": "2022-12-16T22:44:04.873380Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import latexify\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d4df0f",
   "metadata": {},
   "source": [
    "# Notações\n",
    "- Vetores ou data points multidimensionais serão representados pela notação com barra como $\\bar{X}$ ou $\\bar{y}$.\n",
    "- Os produtos entre vetores serão representandos com pontos centralizados $\\bar{X}$ ${\\cdot}$ $\\bar{Y}$.\n",
    "- Uma matrix será representada por uma letra maíscula sem barra, como R.\n",
    "- Matrizes n × d correspondem a todo o data set de treinamento, denotado por D, com n pontos de dados e d dimensões.\n",
    "- Os data points individuais em D são vetores linhas d-dimensionais e são denotados por $\\bar{X}$1... $\\bar{X}$n\n",
    "- Vetores com um componente para cada data point são vetores colunas n-dimensionais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82811762",
   "metadata": {},
   "source": [
    "# Álgebra Linear e Otimização: Uma Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0102d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T19:53:39.326906Z",
     "start_time": "2022-11-14T19:53:39.321124Z"
    }
   },
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc44b5",
   "metadata": {},
   "source": [
    "- Modelos de machine learninig contrõem modelos matemáticos a partir dos dados, que contêm multiplos atributos ou variáveis. \n",
    "- O relacionamento entre o modelo e os dados são expressos de forma linear ou não linear.\n",
    "- Esses relacionamentos são descobertos de forma data driven otimizando (maximizando) o ajuste (\"agreement\") entre o modelo e os dados observados\n",
    "- Álgebra linear é o *estudo de operações lineares em espaços vetoriais*. Um espaço vetorial é o conjunto infinito de todas as coordenadas cartesianas em duas dimensões em relação a um ponto fixo, a origem. Álgebra linear pode ser vista como uma forma de generalização da geometria de coordenadas Cartesiana em d-dimensões.\n",
    "- Em machine learning, o conjunto de dados é representado com multiplas dimensões (atributos).\n",
    "- Uma prática comum é aplicar funções lineares a vetores com alta dimencionalidade para extrair suas propriedades analíticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1208a2",
   "metadata": {},
   "source": [
    "## Scalars, Vetores e Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d55ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T11:40:33.435515Z",
     "start_time": "2022-11-15T11:40:33.428005Z"
    }
   },
   "source": [
    "<img src=\"scalar-vector-matrix.jpg\">\n",
    "\n",
    "\n",
    "- Scalars: São valores numéricos individuais normalmente extraídos do domínio real em machine learning, como o atritubo \"idade\".\n",
    "\n",
    "- Vetores: São arrays de valores numéricos (arrays de escalares). Também são referidos como coordenadas. Os valores numéricos individuais dos arrays são chamados de entidades, componentes ou dimensões do vetor. E o número de componentes é referido como dimensionalidade do vetor. Um vetor de 3 dimensões de uma pessoa de 25 anos, fazendo 30 USD por hora e possuindo 5 anos de experiência é representado como um array com os números [25, 30, 5]\n",
    "\n",
    "- Matrizes: São arrays de números retangulares que contêm linhas e colunas. Para acessarmos o elemento na matriz, devemos especificar o índice da linha e o índice da coluna (i, j). O tamanho da matriz é denotada por n x d, sendo n o número de indivíduos e d o número de dimensões. Quando uma matriz possui o mesmo número de linhas e colunas, é chamada de square matrix ou matriz quadrada, nos demais casos de matriz retangular.\n",
    "\n",
    "- Por padrão, vetores são assumidos como vetores coluna em álgebra linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c4216",
   "metadata": {},
   "source": [
    "### Operações Básicas com Scalars e Vetores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9df1ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T12:33:14.191627Z",
     "start_time": "2022-11-15T12:33:14.186862Z"
    }
   },
   "source": [
    "- Vetores de mesma dimensionalidade podem ser somados ou subtraídos.\n",
    "- Considerando dois vetor de d-dimensões $\\bar{x} = [x1... xd]$ e $\\bar{y} = [yi...yd]$, podem ser somados como \n",
    "\n",
    "<center> $$ \\bar{x} + \\bar{y}$ = $[xi...xd] + [yi...yd] = [x1 + y1... xd + yd] $$ </center>\n",
    "\n",
    "assim como subtraídos da mesma forma \n",
    "\n",
    "<center> $$ \\bar{x} + \\bar{y} = [xi...xd] - [yi...yd] = [x1 - y1... xd - yd] $$ </center>\n",
    "\n",
    "- A adição de vetores é comutativa (como adição escalar) porquê $\\bar{x}$ + $\\bar{y}$ = $\\bar{y}$ + $\\bar{x}$. A comutatividade da adição, ou simplesmente propriedade comutativa, diz para gente que a ordem da adição não importa, sempre chegaremos ao mesmo resultado. Ou seja, 2 + 3 é igual a 3 + 2, pois 3 + 2 é igual a 5, da mesma forma que 2 + 3 também é igual a 5.\n",
    "\n",
    "- É possível multiplicar um vetor com um escalar, multiplicando cada elemento do vetor com o escalar. Multiplicando o vetor $\\bar{x} = [x1... xd]$ escalado pelo fator de a\n",
    "\n",
    "<center> $$ \\bar{x}' = a\\bar{x} = [ax1...axd] $$ </center>\n",
    "\n",
    "- Um comprimento (length) do vetor pode ser escalado, não alterando a sua direção com uma multiplicação escalar. Considere o vetor $\\bar{x}$ contendo o número de unidades vendidas de um produto, o número de unidades vendidas pode ser convertida em milhões de unidades vendidas ao multiplicar o vetor com a = 10⁻⁶.\n",
    "\n",
    "- Os vetores podem ser multiplicados com a noção do produto escalar (dot produt). **O produto escalar entre dois vetores é a soma da multiplicação elemento a elemento de seus componentes individuais.** \n",
    "\n",
    "<center> $$ \\bar{x} \\cdot \\bar{y} = \\sum_{i=1}^{d} xiyi $$ </center>\n",
    "\n",
    "- [inserir gif de multiplicação de matrizes]***\n",
    "\n",
    "- O produto escalar dos vetores $\\bar{x}$ = [1, 2, 3] e $\\bar{y}$ = [6, 5, 4] pode ser computado da seguinte forma:\n",
    "\n",
    "<center> $$ \\bar{x} \\cdot \\bar{y} = (1)(6) + (2)(5) + (3)(4) = 28 $$ </center> \n",
    "\n",
    "- O produto escalar é um caso especial de uma operação mais geral, chamada de produto interno, e preserva muitas regras fundamentais da geometria euclidiana. O espaço de vetores que inclui uma operação de produto escalar é chamado de espaço euclidiano. O produto escalar é uma operação comutativa\n",
    "\n",
    "<center> $$ \\bar{x} \\cdot \\bar{y} = \\sum_{i=1}^{d} xiyi = \\sum_{i=1}^{d}yixi = \\bar{y} \\cdot \\bar{x}$$</center>\n",
    "\n",
    "- O produto escalar também herda as propriedades distributivas da multiplicação escalar. A propriedade distributiva é utilizada quando um número está multiplicando uma adição ou subtração. Basta multiplicar separado cada termo e, somar ou subtrair o resultado. Nós distribuímos a multiplicação do 2, para o 8 e para o 3. Uma dica importante é colocar em evidência.\n",
    "\n",
    "<center>$$ \\bar{x} \\cdot (\\bar{y}+\\bar{z}) = \\bar{x} \\cdot \\bar{y} + \\bar{x} \\cdot \\bar{z} $$</center>\n",
    "\n",
    "- O produto escalar de um vetor $\\bar{x} = [x1... xd]$ com ele mesmo é chamado **norma quadrada (squared norm)** ou [**norma Euclidiana**](https://www.youtube.com/watch?v=41XmlK7itG8). Essa norma define o comprimento do vetor e é denotado por $||\\cdot||$\n",
    "\n",
    "<center> $$||\\bar{x}||^{2} = \\bar{x} \\cdot \\bar{x} = \\sum_{i=1}^{d}x_{i}^{2}$$ </center>\n",
    "\n",
    "- **A norma (comprimento) de um vetor é a distância** Euclidiana de suas coordenadas a partir de sua origem.\n",
    "\n",
    "<center> $$\\bar{v} = \\sqrt{ (c-a)^{2} + (d-b)^2 } $$</center>\n",
    "\n",
    "<center> <img src=\"norma-do-vetor-v(1).png\"> $$</center>\n",
    "\n",
    "Frequentemente os vetores são normalizados para o comprimento unitário dividindo eles pela sua norma\n",
    "\n",
    "<center> $$\\bar{x}' = \\frac{\\bar{x}}{||\\bar{x}||} = \\frac{\\bar{x}}{\\sqrt{\\bar{x} \\cdot \\bar{x}}}$$ </center>\n",
    "\n",
    "- Dimensionar (scaling) um vetor por sua norma não altera os valores relativos de seus componentes, que definem a direção do vetor. Por exemplo, a distância euclidiana de [4, 3] da origem é 5. A divisão de cada componente do vetor por 5 resulta no vetor [4/5, 3/5], que altera o comprimento do vetor para 1, mas não sua direção. O vetor resultante é chamado de vetor unitário.\n",
    "\n",
    "Uma generalização da norma Euclidiana é a $L_{p}-norm$, que é denotada por $||\\cdot||_{p}$:\n",
    "\n",
    "<center> $$ ||\\bar{x}||_{p} = (\\sum_{i=1}^{d}|xi|^{p})^{(1/p)} $$ </center>\n",
    "\n",
    "Aqui, $|\\cdot|$ indica o valoe absoluto do escalar, e o p é um inteiro positivo. Por exemplo, quando p é definido como 1, a norma resultante é referida como norma Manhattan ou $L_{1}-norm\n",
    "\n",
    "- A distância Euclidiana quadrada entre $\\bar{x} = [x1,... xd]$ e $\\bar{y} = [y1,... yd]$ pode ser mostrada pelo produto escalar de $\\bar{x}-\\bar{y}$ com ele mesmo, como:\n",
    "\n",
    "<center> $$ ||\\bar{x}-\\bar{y}||^{2} = (\\bar{x}-\\bar{y}) \\cdot (\\bar{x}-\\bar{y}) = \\sum_{i=1}^{d}(xi-yi)^{2} = Euclidian(\\bar{x}, \\bar{y})^{2} $$ </center>\n",
    "\n",
    "- Produtos escalares satisfazem a [desigualdade de Cauchy-Schwarz](https://pt.wikipedia.org/wiki/Desigualdade_de_Cauchy-Schwarz), segundo a qual o produto escalar entre um par de vetores é limitado acima pelo produto de seus comprimentos\n",
    "\n",
    "<center> $$ |\\sum_{i=1}^{d}xiyi = |\\bar{x}\\cdot\\bar{y}| \\leq ||\\bar{x}||  ||\\bar{y}|| $$ </center>\n",
    "\n",
    "- A desigualdade de Cauchy-Schwarz mostra que **o produto escalar entre um par de vetores não é maior que o produto dos comprimentos dos vetores**. A desigualdade de Cauchy-Schwarz pode ser provada promeiro mostrando que $|\\bar{x}\\cdot\\bar{y}| \\leq 1$ quando $\\bar{x}$ e $\\bar{y}$ são vetores unitários, ou seja, o resultado é válido quando so argumentos são vetores unitários. Isso porquê ambos $||\\bar{x}-\\bar{y}||^{2} = 2-2\\bar{x}\\cdot\\bar{y}$ e $||\\bar{x}+\\bar{y}||^{2} = 2+2\\bar{x}\\cdot\\bar{y}$ são não negativos. Isso é possível quando $|\\bar{x}\\cdot\\bar{y}| \\leq 1$. Pode-se então generalizar esse resultado para vetores de comprimento arbitrário observando que o produto escalar aumenta linearmente com as normas dos argumentos subjacentes. Portanto, pode-se escalar ambos os lados da desigualdade com as normas dos vetores.\n",
    "\n",
    "Exemplos:\n",
    "- [Desigualdade de Cauchy-Schwarz](https://www.youtube.com/watch?v=cuq5om9TAPQ)\n",
    "- [Desigualdade de Cauchy-Schwarz](https://www.youtube.com/watch?v=IxxIyceUAXA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4badef6",
   "metadata": {},
   "source": [
    "### Operações Básicas com Vetores e Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfd60b",
   "metadata": {},
   "source": [
    "- Uma matriz transposta é obtida invertendo as linhas e colunas. Sendo assim, a (i, j)-ésima entrada da transposta é o mesmo que a (j, i) entrada da matriz original. A transposta de uma matriz n x d é uma matriz d x n. Uma matriz transposta é denotada com o \"t\" elevado, como $A^{T}$.\n",
    "\n",
    "<matriz transposta>\n",
    "\n",
    "<center> $$\\begin{bmatrix} a11 & a12\\\\ a21 & a22 \\\\ a31 & a32 \\end{bmatrix}^{T} =  \\begin{bmatrix} a11 & a21 & a31\\\\ a12 & a22 & a32 \\end{bmatrix} $$</center>\n",
    "\n",
    "- Assim como vetores, matrizes podemos fazer operações de adição, desde que possuam o mesmo tamanho. A adição de matrizes é comutativa.\n",
    "\n",
    "<center>$$ A + B = B + A $$</center>\n",
    "\n",
    "- Uma matriz zero ou nula é uma matriz que contêm somente valores 0. As somas feitas com ela não afetam os valores.\n",
    "\n",
    "<center>$$ A + 0 = A $$</center>\n",
    "\n",
    "- A soma de deuas matrizes transpostas $A = [a_{ij}]$ e $B = [b_{ij}]$ é dada pela soma de suas transpostas\n",
    "\n",
    "<center>$$ (A + B)^{T} = A^{T} + B^{T} $$</center>\n",
    "\n",
    "- Também podemos realizar multiplicação entre matrizes. Uma matriz n x d pode ser multiplicada por um vetor coluna d-dimensional $\\bar{x}$ como $A\\bar{x}$, ou, pode ser multiplicada com um vetor linha n-dimensional $\\bar{y}$ como $\\bar{x}A$. Quando uma matriz é multiplicada por um vetor coluna, uma multiplicação elemento a elemento é feita entre os d-elementos de cada linha da matriz.\n",
    "\n",
    "<center>$$ \\begin{bmatrix} a11 & a12\\\\ a21 & a22\\\\ a31 & a32 \\end{bmatrix} \\begin{bmatrix} x1\\\\ x2 \\end{bmatrix} = \\begin{bmatrix} a11x1 + & a12x2\\\\ a21x1 + & a22x2\\\\ a31x1 + & a32x2 \\end{bmatrix} $$ </center>\n",
    "\n",
    "- A multiplicação entre matrizes e vetores **não é comutativa**.\n",
    "\n",
    "- Uma multiplicação de uma matriz n x d com um vetor coluna d-dimensional $\\bar{x}$ cria um vetor coluna n-dimensional $A\\bar{x}$. Isso é interpretado como uma transformação linear de um espaço d-dimensional para um espaço n-dimensional. O resultado de uma multiplicação é a soma ponderada das colunas da matriz Z, onde os pesos são dados pelos componentes escalares do vetor $\\bar{x}$.\n",
    "\n",
    "<center>$$ \\begin{bmatrix} a11 & a12\\\\ a21 & a22\\\\ a31 & a32 \\end{bmatrix} \\begin{bmatrix} x1\\\\ x2 \\end{bmatrix} = x1 \\begin{bmatrix} a11\\\\ a21\\\\ a31\\end{bmatrix} + x2 \\begin{bmatrix} a12\\\\ a22\\\\ a32 \\end{bmatrix} $$</center>\n",
    "\n",
    "Aqui, um vetor 2-dimensional é mapeado em um vetor 3-dimensional como a combinação ponderada das colunas da matriz. Isso resulta na forma de uma multiplicação matriz-vetor usando a coluna A e a coluna vetor $\\bar{x} = [x_{1}, ... x_{d}]^{T}$ de coeficientes.\n",
    "\n",
    "<center>$$ A\\bar{x} = \\sum_{i=1}^{d}x_{i}\\bar{a}_{i} = \\bar{b} $$</center>\n",
    "\n",
    "Aqui, cada xi corresponde ao \"peso\" da i-ésima direção de $\\bar{a}_{i}$, também chamada de i-ésima **coordenada** de \\{b} usando as direções contidas em A.\n",
    "\n",
    "- O produto escalar entre dois vetores pode ser visto como um caso especial de multiplicação amtriz-vetor. Nesse caso, uma matriz 1xd (vetor linha) é multiplicada com uma matriz dx1 (vetor coluna), e o resultado é o mesmo que obteríamos performando um produto escalar entre dois vetores.\n",
    "\n",
    "<center>$$ \\bar{x} \\cdot \\bar{x} = [v1, v2, v3] \\begin{bmatrix} x1\\\\ x2 \\\\ x3 \\end{bmatrix}\n",
    "= [v1x1 + v2x2 + v3x3] $$</center>\n",
    "\n",
    "- O resultado de uma multiplicação de matriz é uma matriz 1x1 contendo o produto escalar, que é um escalar\n",
    "\n",
    "<center>$$\\bar{x} \\cdot \\bar{v} = \\bar{v} \\cdot \\bar{x}, \\bar{x}^{T}\\bar{v} = \\bar{v}^{T}\\bar{x} $$</center>\n",
    "\n",
    "O produto escalar é comutativo nesse caso.\n",
    "\n",
    "- Se ordenarmos a \"matriz alta\" antes da \"matriz larga\", o que vamos obter é um produto externo (outer product). O produto externo entre dois vetores 3-dimensionais é uma matriz 3x3.\n",
    "\n",
    "<center>$$ \\bar{x} \\otimes \\bar{v} = \\bar{x}\\bar{v}^{T} = \\begin{bmatrix} x1\\\\ x2 \\\\ x3 \\end{bmatrix} [v1, v2, v3] =  \\begin{bmatrix} v1x1 & v2x1 & v3x1\\\\ v1x2 & v2x2 & v3x2\\\\ v1x3 & v2x3 & v3x3\\\\ \\end{bmatrix} $$</center>\n",
    "\n",
    "- Diferente de produto escalar, o produto externo pode ser executado entre dois vetores de diferentes tamanhos e **não é comutativo**.\n",
    "\n",
    "<center>$$ \\bar{x} \\otimes \\bar{v} \\neq \\bar{v} \\otimes \\bar{x}, \\bar{x}\\bar{v}^{T} \\neq \\bar{v}\\bar{x}^{T} $$</center>\n",
    "\n",
    "- A multiplicação entre dois vetores ou entre matrizes e vetores é um caso espacial de multiplicação entre matrizes. As operações de produto escalar dentro da multiplicação exigem que os vetores subjacentes sejam do mesmo tamanho\n",
    "\n",
    "<center>$$ (UV)_{ij} = \\sum_{r=1}^{k}u_{ir}v_{rj} $$</center>\n",
    "\n",
    "- Um exemplo de multiplicação de matrizes seria:\n",
    "\n",
    "<center>$$ \\begin{bmatrix} u11 & u12\\\\ u21 & u22\\\\ u31 & u32 \\end{bmatrix} \\begin{bmatrix} v11 & v12 & v13\\\\ v21 & v22 & v23 \\end{bmatrix} = \\begin{bmatrix} u11v11 + & u12v21 & u11v12 + u12 & u11v13 + u12+v13\\\\ u21v11 + & u22v21 & u21v12 + u22v22 & u21v13 + u22+v13\\\\ u31v11 + & u32v21 & u31v12 + u32v22 & u31v13 + u32+v13\\\\ \\end{bmatrix} $$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239dfab",
   "metadata": {},
   "source": [
    "### Classes Especiais de Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78a772",
   "metadata": {},
   "source": [
    "- Uma matriz simétrica é uma matriz quadrada que é igual a sua transposta $A = A^{T}$\n",
    "\n",
    "<center>$$ \\begin{bmatrix} 2 & 1 & 3\\\\ 1 & 4 & 5\\\\ 3 & 5 & 6 \\end{bmatrix} $$</center>\n",
    "\n",
    "- A diagonal de uma matriz é definida como um conjunto de entradas em que as linhas e colunas é a mesma.\n",
    "\n",
    "- Uma matriz em que em sua diagonal é composta por 1, e os valores acima, abaixo ou ambos são nulos, é chamada de **matriz identidade**, denotado pela letra $I$ maíscula.\n",
    "\n",
    "- Quando os elementos não-diagonais forem zero e os elementos na diagonal forem diferentes de 1, a matriz é chamada de **matriz diagonal**.\n",
    "\n",
    "- Multiplicar uma matriz A $nxd$ com uma matriz identidade de mesma ordem (tamanho) resulta na mesma matriz A. Podemos ver a matriz identidade como análoga ao valor 1 numa multiplicação escalar.\n",
    "\n",
    "<center>$$ AI = IA = A $$</center>\n",
    "\n",
    "- Uma matriz retangular diagonal é uma matriz $nxd$ em que as entradas (i, j) tem valores não zero se e apenas se i=j. A diagonal das entradas diferentes de zero começam no canto superior esquerdo e não atingem o inferior direito.\n",
    "\n",
    "- Uma matriz diagonal em blocos (block diagonal matrix) contêm blocos quadrados B1...br de possíveis entradas diferentes de zero. Todas as demais entradas são zero. Mesmo que cada bloco seja quadrado, eles não precisam ter o mesmo tamanho.\n",
    "\n",
    "- Uma matriz quadrada é ```upper triangular matrix``` se todas as entradas (i, j) abaixo da diagonal principal (satisfazendo i>j) forem zeros.\n",
    "\n",
    "- Uma matriz quadrada é ```lower triangular matrix``` se todas as entradas (i, j) acima da diagonal principal (satisfazendo i < j) são zeros.\n",
    "\n",
    "- Uma matriz é ***estritamente*** triangular se for triangular e toda a diagonail forem elementos zeros.\n",
    "\n",
    "- A soma ou produto de uma matriz upper triangular é upper triangular.\n",
    "\n",
    "<center> <img src=\"matrix_exemples.png\"> </center>\n",
    "\n",
    "<center> (Aggarwal, 2020) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1f227",
   "metadata": {},
   "source": [
    "### Potência de Matrizes, Polinomiais e Inversas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f572dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T22:27:33.577400Z",
     "start_time": "2022-11-22T22:27:33.574567Z"
    }
   },
   "source": [
    "- Matrizes quadradas podem ser multiplicadas com elas mesmas sem violar a restrição de tamanho da multiplicação de matrizes. Fazer isso é análogo a elevar um escalar a determinada potência.\n",
    "\n",
    "<center>$$ A^{m} = \\underbrace{AA...A$}_{_{n}times} $$</center>\n",
    "\n",
    "- A potência zero de uma matriz é definida como sendo a matriz identidade de mesmo tamanho.\n",
    "\n",
    "- Quando uma matriz satisfaz $A^{k} = 0$ pra algum inteiro k, é chamada de **nilpotent**.\n",
    "\n",
    "- Podemos computar uma função polinomial $f(A)$ de uma matriz quadrada do mesmo jeito que computamos com escalares. Em vez do termo constante usado em um polinômio escalar, são usados múltiplos da matriz identidade; a matriz de identidade é uma matriz análoga ao valor escalar de 1. Por exemplo, uma matriz análoga ao polinômio escalar $f(x) = 3x^{2}+5x+2$ quando aplicado à uma matriz dxd é:\n",
    "<center>$$ f(A) = 3A^{2}+5A+2I $$</center>\n",
    "\n",
    "- Todos os polinômios da mesma matriz A sempre comutam em relação ao operador de multiplicação.\n",
    "\n",
    "- ~~Matrizes polinomiais são comutativas*. ~~ Dois polinômios $f(A)$ e $g(A)$ de uma mesma matriz sempre vão comutar. O produto de uma matriz com sua inversa é sempre comutativo e conduz à matriz identidade (Comutatividade é uma propriedade de operações binárias, ou de ordem mais alta, em que a ordem dos operandos não altera o resultado fina)\n",
    "\n",
    "<center>$$ f(A)g(A) = g(A)f(A)$$</center>\n",
    "\n",
    "- A **inversa** de uma matriz quadrada A é outra matriz quadrada denotada por $$A^{-1}. \n",
    "\n",
    "- A multiplicação dede duas matrizes (em qualquer ordem) resultará numa matriz identidade:\n",
    "\n",
    "<center> $$ AA^{-1} = A^{-1}A = I$$ </center>\n",
    "\n",
    "- Existe uma fórmula simples para inverter matrizes 2 × 2\n",
    "<center>$$  \\begin{bmatrix} a & b \\\\ c & d\\end{bmatrix} = \\frac{1}{ad-bc} \\begin{bmatrix} d & -b\\\\ -c & a \\end{bmatrix} $$</center>\n",
    "\n",
    "- Um exemplo de duas matrizes que são inversas uma da outra:\n",
    "\n",
    "<center>$$ \n",
    "\\begin{bmatrix}8 & 3\\\\5 & 2 \\end{bmatrix} \\begin{bmatrix} 2 & -3\\\\ -5 & 8 \\end{bmatrix}\n",
    "=  \\begin{bmatrix} 2 & -3\\\\ -5 & 8 \\end{bmatrix}\\begin{bmatrix}8 & 3\\\\5 & 2 \\end{bmatrix} = \\begin{bmatrix}1 & 0\\\\0 & 1 \\end{bmatrix} $$</center>\n",
    "\n",
    "- A inversa de uma matriz 1 × 1 contendo o elemento a é simplesmente a matriz 1 × 1 contendo o elemento 1/a. Portanto, uma matriz inversa naturalmente generaliza uma escalar inversa. Nem todas as matrizes possuem inversas, assim como não existe inversa para o escalar a = 0.\n",
    "\n",
    "- Uma matriz para a qual existe uma inversa é referida como invertível ou não singular. Caso contrário, diz-se que é singular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e803f64",
   "metadata": {},
   "source": [
    "### Norma de Frobenius, Trace e Energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb93e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2c1dd5f",
   "metadata": {},
   "source": [
    "## Multiplicação de Matrizes como Decomposable Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee84d1ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T22:44:04.908295Z",
     "start_time": "2022-12-16T22:44:04.905122Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2157153464.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_84761/2157153464.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \\begin{bmatrix}\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# exemplo de matriz em latex\n",
    "\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "a & b & c\n",
    "\\end{bmatrix}\n",
    "\n",
    "# lista de simbolos matemáticos: https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e46c3",
   "metadata": {},
   "source": [
    "### Multiplicação de MAtrizes como Decomposable Row e Column Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b7552",
   "metadata": {},
   "source": [
    "### Multiplicação de MAtrizes como Decomposable Geometric Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fc4a0",
   "metadata": {},
   "source": [
    "## Problemas Básicos em Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00cd79",
   "metadata": {},
   "source": [
    "### Fatorização de Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e9801",
   "metadata": {},
   "source": [
    "### Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e610237",
   "metadata": {},
   "source": [
    "### Modelagem de Classificação e Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c8b11",
   "metadata": {},
   "source": [
    "### Detecção de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd83fb9",
   "metadata": {},
   "source": [
    "## Otimização para Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474258ec",
   "metadata": {},
   "source": [
    "### Expansão de Taylor para Simplificação de Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1882738",
   "metadata": {},
   "source": [
    "### Exemplos de Otimização em Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f66906",
   "metadata": {},
   "source": [
    "### Otimização em Grafos Computacionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f31bf",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065f9ea",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3767ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd6731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69834b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7518e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4144f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d1b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d5073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91daebda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae57b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ef165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6708927e",
   "metadata": {},
   "source": [
    "- latex on jupyter notebook https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd\n",
    "- latexfy\n",
    "https://colab.research.google.com/drive/1MuiawKpVIZ12MWwyYuzZHmbKThdM5wNJ?usp=sharing#scrollTo=hViDMhyMFNCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781fe24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T22:44:04.910113Z",
     "start_time": "2022-12-16T22:44:04.910098Z"
    }
   },
   "outputs": [],
   "source": [
    "# ocultar células"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.465px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
