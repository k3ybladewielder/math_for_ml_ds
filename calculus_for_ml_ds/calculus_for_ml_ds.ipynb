{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8d6bf4",
   "metadata": {},
   "source": [
    "# Calculus for Machine Learning and Data Science\n",
    "\n",
    "Notas sobre o curso Calculus for Machine Learning and Data Science da DeeplearninigAI.\n",
    "\n",
    "Repositório com a trilha Mathematics for Machine Learninig and Data Science:\n",
    "https://github.com/k3ybladewielder/math_for_ml_ds\n",
    "\n",
    "Fórum do curso: https://community.deeplearning.ai/c/math-for-machine-learning/m4ml-course-2/304"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81350273",
   "metadata": {},
   "source": [
    "# Week 1 - Derivatives and Optimization\n",
    "\n",
    "Objectives\n",
    "- Perform gradient descent in neural networks with different activation and cost functions\n",
    "- Visually interpret differentiation of different types of functions commonly used in machine learning\n",
    "- Approximately optimize different types of functions commonly used in machine learning using first-order (gradient descent) and second-order (Newton’s method) iterative methods\n",
    "- Analytically optimize different types of functions commonly used in machine learning using properties of derivatives and gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871740fd",
   "metadata": {},
   "source": [
    "## Concept of Derivatives and Tangents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d27e00",
   "metadata": {},
   "source": [
    "A derivada é a taxa instantânea de variação de uma função. É uma medida da taxa de variação instantânea de uma função em relação à sua variável independente. Em outras palavras, a derivada de uma função f(x) em um ponto x é a inclinação da tangente à curva da função nesse ponto. A derivada de uma função num ponto é a inclinação (slope) da tangente nesse ponto. Geometricamente, pode ser entendida como a taxa de mudança (rate of change) da função em um determinado ponto. \n",
    "\n",
    "Exemplo: Imagine que você está andando de bicicleta em uma estrada montanhosa, onde a estrada é a representação da função matemática. A derivada é como a medida de quão rápido você está subindo ou descendo a colina em um ponto específico da estrada. Se você está subindo uma colina íngreme, você está indo devagar, então a derivada é pequena. Se você está descendo a colina rapidamente, você está indo mais rápido, então a derivada é grande.\n",
    "\n",
    "É uma \"força que aplica em cada entrada pra aumentar a saída.\", \"É uma forma inteligente de saber como deve alterar as entradas pra levemente aumentar a sua saída\"\n",
    "\n",
    "A tangente de uma derivada é a reta que toca suavemente uma curva em um ponto específico e representa a taxa de mudança instantânea daquela curva naquele ponto.\n",
    "\n",
    "Imagine que você está desenhando uma curva em um papel, e em algum ponto dessa curva você desenha uma reta que toca suavemente a curva. Essa reta é a tangente da curva naquele ponto, e a inclinação da reta representa a taxa de mudança instantânea da curva naquele ponto (derivada).\n",
    "\n",
    "A tangente de uma derivada é útil porque nos permite entender como uma curva está mudando em um ponto específico e, portanto, pode nos ajudar a prever como ela mudará em outros pontos próximos. A tangente da derivada também é usada em cálculo para encontrar o ponto máximo ou mínimo de uma função, bem como para calcular a velocidade, a aceleração e outras medidas importantes em física e engenharia\n",
    "\n",
    "Em machine learninig, derivada é usada para otimizar funções, pra maximizar ou minimizar um valor de uma função. Isso é feito pra encontrar os parâmetros do modelo que melhor se ajuste aos dados, a partir do cálculo e minimização da loss funcion. \n",
    "\n",
    "<img src=\"./imgs/derivative.png\">\n",
    "\n",
    "O valor máximo ou mínimo ocorre quando da função, acontece quando a derivada é zero. Quando a linha da tangente é horizontal.\n",
    "\n",
    "<img src=\"./imgs/maxima.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cce535",
   "metadata": {},
   "source": [
    "## Derivatives and their notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816df2d",
   "metadata": {},
   "source": [
    "Sabemos que a inclinação (slope) é calculada como a variação do X sobre o Y, sendo $\\frac{\\Delta x}{\\Delta y}$. Assim, a inclunação num ponto específico é $\\frac{dx}{dt}$. No geral, usamos o X no eixo horizontal e Y no eixo vertical, logo, a derivada fica como $\\frac{dx}{dy}$\n",
    "\n",
    "Sendo sua função $$ y = f(x)$$ representamos a derivada usando a **notação de Lagrange** como:\n",
    "\n",
    "<center>$$f'(x)$$</center>\n",
    "\n",
    "\n",
    "Também podemos representar a derivada usando a **notação de Leibniz**:\n",
    "<center>$$ \\frac{dy}{dx} = \\frac{d}{dx}f(x)$$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db9fb3",
   "metadata": {},
   "source": [
    "## Some common Derivatives - Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4313d59",
   "metadata": {},
   "source": [
    "Em retas/linhas, a tangente em todos os pontos é o mesmo. Por isso são as mais simples.\n",
    "\n",
    "Neste primeiro exemplo temos uma constante. Nela, a altura do $x0 = x1 = xn$, ou seja, em qualquer ponto o valor da altura é o mesmo, é constante. Assim como como a tangente, ela é a mesma em todos os pontos, possui a mesma inclunação em qualquer ponto. Aqui, a inclunação é **zero**. Constantes ou linhas horizontais sempre terá a derivada de **zero**\n",
    "\n",
    "<img src=\"./imgs/slope_line1.png\">\n",
    "\n",
    "Neste segundo exemplo, temos a função $f(x) = ax + b$, em que o a é a inclunação da reta e o b é o seu intercepto, ou seja, o ponto em que toca no eixo y. A derivada dessa função é o $\\frac{\\Delta y}{\\Delta x} = a$. Aqui a tangente possui a mesma inclunação em todos os pontos, assim como a constante. Sempre que temos uma reta, todos os pontos possuem a mesma inclinação. Sendo $f'(x) = a$ \n",
    "\n",
    "Imagine que você está andando de bicicleta em uma estrada reta. A sua velocidade é constante, o que significa que você está pedalando na mesma velocidade o tempo todo. Agora, se você começa a acelerar ou desacelerar, a sua velocidade muda, certo?\n",
    "\n",
    "A mesma coisa acontece com uma função matemática. Quando você tem uma função como $f(x) = ax + b$, ela representa uma linha reta no gráfico. Se a \"a\" é positiva, significa que a linha está inclinada para cima, e se a \"a\" é negativa, a linha está inclinada para baixo.\n",
    "\n",
    "A derivada da função f(x) **é a taxa de mudança da inclinação da linha**. Em outras palavras, é o **quanto a linha está inclinada em cada ponto**. Se a função é uma linha reta, a inclinação é sempre a mesma, então a derivada é sempre a mesma - a inclinação da linha, que é o \"a\".\n",
    "\n",
    "Então, em resumo, a derivada de f(x) = ax + b é sempre igual a \"a\", que é a inclinação da linha.\n",
    "\n",
    "<img src=\"./imgs/slope_line2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d48a83",
   "metadata": {},
   "source": [
    "## Some common Derivatives - Quadratics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1314f989",
   "metadata": {},
   "source": [
    "A função quadrática mais simples é uma parábola, com a equação $y = f(x) = x^{2}$. Aqui, à esquerda do eixo Y temos valores negativos e à direita temos valores positivos. A fórmula da sua derivada é $\\frac{\\Delta f}{\\Delta x}$ quando o $\\Delta x$ vai a zero. $\\Delta f$ é a variação em y ou a variação em f, \n",
    "\n",
    "$$\\frac{\\Delta f}{\\Delta x} = \\frac{(x + \\Delta x)^{2} - (x){2}}{\\Delta x} $$\n",
    "\n",
    "Quando x = 1,\n",
    "\n",
    "$$\\Delta f = (1 + 1){2} - 1^{2} = 4 - 1 = 3$$\n",
    "\n",
    "E o $$\\Delta x = 1$$\n",
    "\n",
    "Assim $$\\frac{\\Delta f}{\\Delta x} = \\frac{3}{1} = 3$$\n",
    "\n",
    "Quanto mais diminuímos o intervalo, mais diminuímos o $\\Delta f$, mais a variação em y diminui. Neste exemplo, quanto mais diminuímos, mais a inclunação se aproxima de 2, isso porquê a inclinação da tangente em 1 é 2. E 2 é 2 vezes 1.\n",
    "\n",
    "$$f'(1) = \\frac{d}{dx}f(1) = 2$$\n",
    "\n",
    "<img src=\"./imgs/slope_quadratic1.png\">\n",
    "\n",
    "Imagine que você tem uma bola e quer saber em que direção ela está indo. Se você olhar para a bola em dois momentos diferentes, você pode ver que ela está se movendo. A derivada é como se você olhasse para a bola em dois momentos e calculasse a velocidade dela.\n",
    "\n",
    "A mesma coisa acontece com a função quadrática f(x) = x². Se você desenha essa função no papel, ela forma uma curva. A derivada dessa função é como se você olhasse para a curva em dois pontos diferentes e calculasse a inclinação dela. E, para essa função, a inclinação muda a cada ponto ao longo da curva.\n",
    "\n",
    "Quando você calcula a derivada de f(x) = x², você obtém f(x) = 2x. Isso significa que a inclinação da curva em cada ponto é igual a 2 vezes o valor de x naquele ponto. Em outras palavras, quanto maior o valor de x, mais íngreme é a curva.\n",
    "\n",
    "Então, em resumo, a derivada da função quadrática f(x) = x² é f(x) = 2x, o que significa que a inclinação da curva muda a cada ponto ao longo da curva e é igual a 2 vezes o valor de x em cada ponto\n",
    "\n",
    "<img src=\"./imgs/slope_quadratic2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c2c70",
   "metadata": {},
   "source": [
    "## Some common Derivatives - Higher Degree Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9d987",
   "metadata": {},
   "source": [
    "A derivada de uma função cúbica é bem parecida com a quadrada, e seu comportamento é semelhante. À medida que $\\Delta x$ vai para zero, esse valor se torna a inclinação da linha tangente ou a derivada. Sua função é \n",
    "\n",
    "$$y = f(x) = x^{3} $$\n",
    "\n",
    "E sua inclinação se dá por:\n",
    "\n",
    "$$\\frac{\\Delta f}{\\Delta x} = \\frac{(x + \\Delta x)^{3} - (x){3}}{\\Delta x} $$\n",
    "\n",
    "Vamos imaginar que você tem uma pilha de blocos que cresce a cada minuto. Se você quiser saber a velocidade com que a pilha está crescendo, você precisa olhar para a pilha em dois momentos diferentes e calcular a diferença entre elas. A derivada é como se você fizesse isso muitas vezes, em um intervalo de tempo muito pequeno, para saber a velocidade exata da pilha.\n",
    "\n",
    "A mesma coisa acontece com a função cúbica f(x) = x³. A derivada dessa função é como se você olhasse para a curva em dois pontos diferentes e calculasse a inclinação dela. E, para essa função, a inclinação também muda a cada ponto ao longo da curva.\n",
    "\n",
    "Quando você calcula a derivada de f(x) = x³, você obtém f(x) = 3x². Isso significa que a inclinação da curva em cada ponto é igual a 3 vezes o valor de x ao quadrado. Em outras palavras, **quanto maior o valor de x, mais íngreme é a curva**, e a **inclinação aumenta mais rapidamente quanto maior o valor de x**.\n",
    "\n",
    "Então, em resumo, a derivada da função cúbica f(x) = x³ é f(x) = 3x², o que significa que a inclinação da curva muda a cada ponto ao longo da curva e é igual a 3 vezes o valor de x ao quadrado em cada ponto.\n",
    "\n",
    "<img src=\"./imgs/slope_cubic1.png\">\n",
    "<img src=\"./imgs/slope_cubic2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ec87e",
   "metadata": {},
   "source": [
    "## Some common Derivatives - Other Power Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86af66",
   "metadata": {},
   "source": [
    "A derivada de uma hipérbota, ou 1/x é um pouco mais complicada, mas o cálculo é relativamente simples. \n",
    "\n",
    "Sua função se dá por\n",
    "\n",
    "$$ y = f(x) = x^{-1} = \\frac{1}{x}$$\n",
    "\n",
    "E sua inclinação\n",
    "\n",
    "$$\\frac{\\Delta f}{\\Delta x} = \\frac{(x + \\Delta x)^{-1} - (x){-1}}{\\Delta x} $$\n",
    "\n",
    "Imagine que você tem uma barra de chocolate e a divide em pedaços iguais. Se você tem 4 pedaços, cada um é um quarto da barra inteira. Se você tem 8 pedaços, cada um é um oitavo da barra inteira. Quanto mais pedaços você tem, menor é cada pedaço.\n",
    "\n",
    "A mesma ideia acontece com a função y = 1/x. Essa função representa uma curva que começa em um ponto muito alto no eixo y, perto do infinito positivo, e vai diminuindo de tamanho à medida que se aproxima do eixo x. Quanto mais perto da origem, menor é o valor da função.\n",
    "\n",
    "A derivada dessa função é como se você dividisse a curva em infinitos pedaços, de tamanho cada vez menor. A cada pedaço, você calcula a inclinação da curva nesse ponto específico. Para a função y = 1/x, a inclinação muda em cada ponto ao longo da curva.\n",
    "\n",
    "Quando você calcula a derivada de y = 1/x, você obtém y' = -1/x². Isso significa que a inclinação da curva em cada ponto é igual a -1 dividido pelo valor de x ao quadrado. Em outras palavras, quanto maior o valor de x, menor é a inclinação da curva. E, quando x se aproxima de zero, a inclinação da curva aumenta muito rapidamente, tornando-se cada vez mais íngreme.\n",
    "\n",
    "Então, em resumo, a derivada da função y = 1/x é y' = -1/x², o que significa que a inclinação da curva muda em cada ponto ao longo da curva e é igual a -1 dividido pelo valor de x ao quadrado em cada ponto.\n",
    "\n",
    "<img src=\"./imgs/slope_hip1.png\">\n",
    "\n",
    "<img src=\"./imgs/slope_hip2.png\">\n",
    "\n",
    "Agora que vimos várias derivadas de potencias, podemos identificar um padrão:\n",
    "- O expoente se torna o fator de multiplicação\n",
    "- O novo expoente é o anterior -1\n",
    "\n",
    "Da mesma forma, se tivermos a função $f(x) = x^{n}$ a derivada será $f'(x) = xn{x-1}$\n",
    "\n",
    "<img src=\"./imgs/slope_pattern.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dbd2d",
   "metadata": {},
   "source": [
    "## The Inverse Function and its Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4db619",
   "metadata": {},
   "source": [
    "Uma função sempre faz alguma coisa, e a função que desfaz isso é a **função inversa**. Por exemplo, se uma função transforma o valor de 3 em 5, então a função inversa vai tornar o valor de 5 em 3. A derivada de uma função inversa tem o mesmo sentido.\n",
    "\n",
    "<img src=\"./imgs/inverse_func.png\">\n",
    "\n",
    "A tangente de cada derivada também terá a mesma ligação, a tangente da derivada de uma função inversa é um reflexo da derivada de uma função correspondente.\n",
    "\n",
    "O g(y) é a função inversa, então a derivada de g é 1/f'(x)\n",
    "\n",
    "<img src=\"./imgs/inverse_function_slope1.png\">\n",
    "\n",
    "<img src=\"./imgs/inverse_function_slope2.png\">\n",
    "\n",
    "<img src=\"./imgs/inverse_function_slope3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf493b",
   "metadata": {},
   "source": [
    "## Derivative of Trigonometric Functions (rever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518dce3",
   "metadata": {},
   "source": [
    "O seno, cosseno e tangente são funções matemáticas que estão relacionadas com ângulos em um triângulo retângulo.\n",
    "\n",
    "O seno é a razão entre o lado oposto ao ângulo e a hipotenusa do triângulo retângulo. De maneira mais simples, podemos pensar no seno como a altura de um ponto no triângulo em relação à sua base.\n",
    "\n",
    "O cosseno é a razão entre o lado adjacente ao ângulo e a hipotenusa do triângulo retângulo. Podemos pensar no cosseno como a largura de um ponto no triângulo em relação à sua altura.\n",
    "\n",
    "A tangente é a razão entre o lado oposto ao ângulo e o lado adjacente ao ângulo no triângulo retângulo. Podemos pensar na tangente como a inclinação de um ponto no triângulo em relação à base.\n",
    "\n",
    "As funções trigonométricas como o seno, cosseno e tangente são comumente utilizadas em machine learning para modelar relações não lineares em dados. Uma das maneiras de utilizar essas funções é através de suas derivadas.\n",
    "\n",
    "As derivadas das funções trigonométricas são úteis em machine learning para encontrar a inclinação ou a taxa de variação da função em um determinado ponto. Isso é especialmente útil em algoritmos de otimização, onde a tarefa é encontrar o mínimo ou máximo de uma função.\n",
    "\n",
    "Por exemplo, em redes neurais, as funções de ativação são frequentemente escolhidas para serem não lineares, a fim de permitir que o modelo capture relações complexas nos dados. As funções trigonométricas como o seno e o cosseno podem ser usadas como funções de ativação, como a função seno hiperbólico (tanh), que é uma variação da função seno. A derivada da função seno hiperbólico é facilmente computada a partir da derivada do seno.\n",
    "\n",
    "A tangente também pode ser utilizada como função de ativação em redes neurais, e sua derivada é útil para o cálculo do gradiente, que é fundamental em algoritmos de aprendizado de máquina, como o backpropagation.\n",
    "\n",
    "Assim como o seno e o cosseno, a tangente também é uma função periódica e contínua em todo o seu domínio. A tangente de um ângulo pode ser negativa, zero ou positiva, dependendo do quadrante em que o ângulo se encontra.\n",
    "\n",
    "A **derivada do seno(x)** é **igual ao consseno(x)**, e o mesmo acontece com o cosseno(x). A **derivada do cosseno(x)** é o **-seno(x)**. Isso acontece porquê\n",
    "\n",
    "<img src=\"./imgs/derivada_seno.png\">\n",
    "<img src=\"./imgs/derivada_cosseno.png\">\n",
    "\n",
    "\n",
    "A derivada é uma medida da taxa de variação de uma função em relação à sua variável independente. No caso das funções trigonométricas, a derivada pode ser entendida de forma intuitiva como a taxa de variação da posição do ponto que se move sobre uma circunferência unitária.\n",
    "\n",
    "Para entender por que a derivada do seno(x) é igual ao cosseno(x), podemos imaginar um ponto P que se move sobre uma circunferência unitária, começando no ponto (1,0) no eixo x. A medida que o ponto P se move no sentido anti-horário, a coordenada y do ponto P aumenta e a coordenada x diminui. A taxa de variação do y em relação a x é exatamente a inclinação da reta tangente ao ponto P na circunferência unitária.\n",
    "\n",
    "A inclinação da reta tangente é igual à coordenada x do ponto P, que é exatamente o cosseno do ângulo x. Portanto, a derivada do seno(x) é igual ao cosseno(x).\n",
    "\n",
    "Da mesma forma, podemos entender por que a derivada do cosseno(x) é o -seno(x). Quando o ponto P se move no sentido anti-horário sobre a circunferência unitária, a coordenada x do ponto P diminui e a coordenada y aumenta. A taxa de variação do x em relação a y é exatamente a inclinação da reta tangente ao ponto P na circunferência unitária.\n",
    "\n",
    "A inclinação da reta tangente é igual à coordenada y do ponto P multiplicada por -1, que é exatamente o -seno do ângulo x. Portanto, a derivada do cosseno(x) é o -seno(x).\n",
    "\n",
    "<img src=\"./imgs/trigonometric_func1.png\">\n",
    "<img src=\"./imgs/trigonometric_func2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95694228",
   "metadata": {},
   "source": [
    "## Meaning of the Exponential (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860ab0f",
   "metadata": {},
   "source": [
    "A exponencial (e) é uma constante matemática aproximadamente igual a 2,71828. Ela é uma das funções matemáticas mais importantes e é usada em diversas áreas da ciência, incluindo física, química, engenharia, economia e estatística.\n",
    "\n",
    "A exponencial pode ser definida como a função matemática que descreve o crescimento exponencial de uma quantidade ao longo do tempo.\n",
    "\n",
    "A exponencial também pode ser vista como uma função que cresce muito rapidamente com o aumento de x. Por exemplo, quando x é igual a 1, e^x é aproximadamente igual a 2,71828. Quando x é igual a 2, e^x é aproximadamente igual a 7,389. E quando x é igual a 3, e^x é aproximadamente igual a 20,086. Isso significa que a exponencial cresce muito rapidamente com o aumento de x, e é uma função muito importante em diversos contextos da matemática e da ciência.\n",
    "\n",
    "Uma das aplicações mais comuns é no cálculo de funções de ativação em redes neurais artificiais. A função sigmóide, que tem a forma 1/(1+e^(-x)). Essa função é uma transformação da função exponencial que mapeia qualquer valor real para um valor entre 0 e 1. Ela é usada para \"suavizar\" a saída de cada neurônio, de forma que o resultado final da rede neural seja mais fácil de interpretar.\n",
    "\n",
    "Outra aplicação comum da exponencial em machine learning é na modelagem de processos de crescimento exponencial. Por exemplo, quando estamos modelando o crescimento de uma população, podemos usar uma função exponencial para descrever a taxa de crescimento ao longo do tempo. Essa função pode ser ajustada aos dados reais de uma população usando técnicas de regressão, permitindo que possamos prever o crescimento futuro da população com base nos dados históricos.\n",
    "\n",
    "Além disso, a exponencial também é usada em outras técnicas de machine learning, como o algoritmo de gradient descent, que é usado para ajustar os parâmetros de um modelo de machine learning para que ele se ajuste aos dados de entrada. A exponencial é uma ferramenta matemática muito importante em machine learning, permitindo que os algoritmos sejam ajustados e otimizados para obter os melhores resultados possíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a133dc",
   "metadata": {},
   "source": [
    "## Derivative of e^x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6fcfc",
   "metadata": {},
   "source": [
    "A derivada de um exponencial $e^{x}$ é o próprio $e^{x}$.\n",
    "\n",
    "A forma mais intuitiva de entender por que a derivada da exponencial $e^{x}$ é igual a ela mesma, $e^{x}$, é pensar na própria definição da função exponencial. A função exponencial $e^{x}$ representa o **crescimento exponencial de uma quantidade ao longo do tempo**. Isso significa que, quanto maior o valor de $x$, maior será o valor de $e^{x}$.\n",
    "\n",
    "Quando encontramos a derivada da função exponencial $e^{x}$, estamos essencialmente medindo a taxa de crescimento instantânea da função em um ponto específico. Podemos pensar nessa taxa de crescimento como a inclinação da reta tangente à curva da função exponencial em um ponto específico.\n",
    "\n",
    "Ao calcular a derivada da exponencial, estamos basicamente perguntando \"quanto a função está crescendo neste ponto específico?\". E a resposta é que a função está crescendo a uma taxa exatamente igual ao seu próprio valor, ou seja, a inclinação da reta tangente à curva da função exponencial é igual ao valor da função naquele ponto.\n",
    "\n",
    "Isso ocorre porque, comoa função exponencial é definida como a função que eleva a constante matemática e (aproximadamente 2,71828) à potência x. A derivada da função exponencial $e^{x}$ é encontrada utilizando a regra da cadeia, ou seja, uma fórmula para encontrar a derivada de uma função composta, como é o caso da exponencial.\n",
    "\n",
    "Seja $f(x) = e^{x}$, então:\n",
    "\n",
    "$$ f'(x) = (e^{x})' = e^{x} * (x)' = e^x * 1 = e^{x} $$\n",
    "\n",
    "Portanto, a derivada da exponencial e^x é igual a ela mesma, e^x. Isso significa que a inclinação da reta tangente à curva da função exponencial é igual ao valor da função naquele ponto específico.\n",
    "\n",
    "Dessa forma, podemos entender intuitivamente que a taxa de crescimento instantânea da função exponencial é igual ao seu próprio valor, ou seja, a função exponencial cresce proporcionalmente à sua magnitude em cada ponto, resultando na inclinação da reta tangente igual ao valor da função naquele ponto.\n",
    "\n",
    "<img src=\"./imgs/derivative_e.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b736ff9",
   "metadata": {},
   "source": [
    "## Meaning of the Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebf7ba",
   "metadata": {},
   "source": [
    "O logaritmo é uma ferramenta matemática usada para simplificar cálculos com números muito grandes ou muito pequenos. De forma intuitiva, o logaritmo é o expoente a que uma base deve ser elevada para produzir um determinado número. Por exemplo, se tivermos a equação $10^{3} = 1000$, podemos reescrevê-la como log base $10$ de $1000 = 3$. Isso significa que o logaritmo de $1000$ na base $10$ é igual a $3$. Isso porquê $10^{3} = 1000$. **O logaritmo nos diz quantas vezes a base deve ser multiplicada por si mesma para produzir um determinado número**.\n",
    "\n",
    "O logaritmo é usado em Machine Learning (ML) em diversas situações, mas uma das mais comuns é na normalização de dados. Em muitos casos, os dados usados em ML podem variar significativamente em magnitude e escala, o que pode dificultar a análise e a comparação entre eles. Ao aplicar uma transformação logarítmica nos dados, é possível reduzir a variação de escala e trazer os dados para uma faixa mais próxima. Isso pode facilitar a análise e melhorar o desempenho dos modelos. Por exemplo, se tivermos dados que variam de 1 a 10.000, aplicar uma transformação logarítmica nesses dados fará com que eles variem de 0 a 4 (log base 10 de 1 é 0 e de 10.000 é 4). Dessa forma, podemos trabalhar com os dados normalizados e compará-los de maneira mais adequada.\n",
    "\n",
    "Agora, a **derivada de um logaritmo** é utilizado especialmente na otimização de funções de custo (ou loss functions) em algoritmos de aprendizado de máquina em algoritmos como regressão logística, para modelar as relações não lineares entre as variáveis independentes e dependentes.\n",
    "\n",
    "Em muitos casos, o objetivo do aprendizado de máquina é encontrar um conjunto de parâmetros de modelo que minimizem a função de custo. A **derivada do logaritmo** é usada para encontrar o mínimo dessa função de custo.\n",
    "\n",
    "Por exemplo, em regressão logística, a função de custo é dada pela entropia cruzada (cross-entropy), que é uma função logarítmica. A **derivada dessa função** em relação aos parâmetros do modelo é usada no algoritmo de otimização para **atualizar os pesos** do modelo em cada etapa de treinamento. Isso ajuda a ajustar os pesos do modelo de forma a minimizar o erro e melhorar o desempenho do modelo.\n",
    "\n",
    "Além disso, a derivada do logaritmo é usada em outras técnicas de aprendizado de máquina, como na regularização L1 e L2, que são usadas para evitar o overfitting e aumentar a generalização do modelo. Nesse caso, a derivada é usada para calcular a penalidade adicionada à função de custo, que ajuda a evitar pesos muito grandes no modelo.\n",
    "\n",
    "A **derivada do logaritmo** é uma ferramenta essencial em Machine Learning, sendo usada para encontrar os mínimos das funções de custo e para implementar técnicas de regularização que ajudam a evitar o overfitting e aumentar a generalização do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628ad38",
   "metadata": {},
   "source": [
    "## Derivative of log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566ac55",
   "metadata": {},
   "source": [
    "**A função logarítmica inversa é a exponencial, e vice-versa**. Isso significa que a derivada do logaritmo natural (ou neperiano) pode ser encontrada utilizando a regra da cadeia e as propriedades da exponencial.\n",
    "\n",
    "Uma maneira intuitiva de entender por que a derivada do logaritmo natural de uma função $y$ é igual a $1/y$ é pensar na relação entre logaritmos e exponenciais.\n",
    "\n",
    "O logaritmo de uma função y é o expoente ao qual a base e (aproximadamente 2,71828) deve ser elevada para obter $y$. Por exemplo, se $y = e^{3}$, então o logaritmo natural de $y$ é $log(y) = ln(e^{3}) = 3$.\n",
    "\n",
    "A derivada do logaritmo natural de uma função $y$ é a taxa de variação instantânea do logaritmo em relação a $y$. Podemos interpretar essa taxa de variação como a inclinação da reta tangente à curva do logaritmo em um ponto específico.\n",
    "\n",
    "Ao calcular a derivada do logaritmo natural, estamos essencialmente perguntando \"quanto o logaritmo está mudando neste ponto específico da curva?\". E a resposta é que o logaritmo natural está mudando a uma taxa proporcional ao inverso do valor da função y naquele ponto. Em outras palavras, quanto menor o valor de $y$, mais rápido o logaritmo natural muda, e quanto maior o valor de y, mais devagar ele muda.\n",
    "\n",
    "Isso ocorre porque a relação entre logaritmos e exponenciais nos diz que a derivada do logaritmo natural é o inverso da função exponencial. Ou seja, a derivada do logaritmo natural é igual a $1/y$, porque a derivada da exponencial $e^{x}$ é igual a ela mesma, $e^{x}$.\n",
    "\n",
    "Dessa forma, podemos entender intuitivamente que a taxa de variação do logaritmo natural é inversamente proporcional ao valor da função y naquele ponto, porque a relação entre logaritmos e exponenciais nos diz que as funções logarítmicas e exponenciais são inversas uma da outra.\n",
    "\n",
    "<img src=\"./imgs/derivative_log.png\">\n",
    "\n",
    "A derivada do logaritmo natural é uma ferramenta importante em machine learning para otimizar modelos de aprendizado de máquina e para calcular probabilidades de eventos.\n",
    "\n",
    "Em machine learning, a otimização de modelos é frequentemente realizada usando técnicas de gradiente descendente, que envolvem a atualização iterativa dos parâmetros do modelo com base na taxa de variação da função de custo em relação a esses parâmetros. A função de custo é tipicamente uma função de log-verossimilhança, que é uma função logarítmica da probabilidade de observar os dados, dadas as configurações dos parâmetros do modelo.\n",
    "\n",
    "A derivada do logaritmo natural é útil para calcular a taxa de variação da função de custo em relação aos parâmetros do modelo. Como a função de custo é uma função logarítmica da probabilidade, a derivada do logaritmo natural da probabilidade é igual à derivada da função de custo. Portanto, é comum calcular a derivada do logaritmo natural da probabilidade para atualizar os parâmetros do modelo usando o gradiente descendente.\n",
    "\n",
    "Além disso, a função de custo é frequentemente modelada como uma distribuição de probabilidade, como a distribuição normal ou a distribuição binomial. A derivada do logaritmo natural da distribuição de probabilidade é usada para calcular a probabilidade de observar os dados, dadas as configurações dos parâmetros do modelo. Isso é importante em muitas aplicações de machine learning, como a classificação de imagens, a detecção de fraudes e a recomendação de produtos, onde o objetivo é maximizar a probabilidade de obter resultados precisos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4655e",
   "metadata": {},
   "source": [
    "## Non Differenciable Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be5988",
   "metadata": {},
   "source": [
    "**Non Differenciable Functions** são funções que não possuem derivada em pelo menos um ponto de seu domínio. Em outras palavras, a inclinação da reta tangente à curva da função não pode ser determinada em pelo menos um ponto.\n",
    "\n",
    "As funções não diferenciáveis podem apresentar diferentes tipos de descontinuidades, como descontinuidades de salto ou descontinuidades infinitas. Essas descontinuidades podem ocorrer em pontos isolados ou em intervalos inteiros do domínio da função.\n",
    "\n",
    "Algumas funções famosas que não são diferenciáveis em pontos específicos incluem a função valor absoluto $(abs(x))$ em $x = 0$ e a função módulo $(|x|)$ em $x = 0$. Essas funções apresentam uma descontinuidade de salto em x=0 e, portanto, não são diferenciáveis nesse ponto.\n",
    "\n",
    "Outras funções famosas que não são diferenciáveis em intervalos inteiros do domínio incluem a função valor absoluto $(abs(x))$ em $x < 0$ e a função chão $(floor(x))$ em todo o seu domínio. Essas funções apresentam descontinuidades infinitas em seus intervalos de não-diferenciabilidade.\n",
    "\n",
    "<img src=\"./imgs/non_diff_funcs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724490db",
   "metadata": {},
   "source": [
    "## Properties of Derivative: Multiplication by Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b6359",
   "metadata": {},
   "source": [
    "A multiplicação de derivadas por escalares é uma propriedade afirma que, **para qualquer função f(x) e qualquer constante c, a derivada de c*f(x) é igual a c vezes a derivada de f(x)**.\n",
    "\n",
    "Podemos entender a multiplicação de derivadas por escalares usando o exemplo da multiplicação por 2, **mas ela se aplica a qualquer constante e a qualquer curva**.\n",
    "\n",
    "Suponha que temos uma função f(x) que representa a posição de um objeto em relação ao tempo e queremos encontrar a velocidade do objeto. A velocidade é dada pela derivada da posição em relação ao tempo.\n",
    "\n",
    "Agora, suponha que o objeto esteja se movendo duas vezes mais rápido. Isso significa que a posição do objeto em relação ao tempo foi multiplicada por 2. Se queremos encontrar a nova velocidade do objeto, precisamos multiplicar a derivada da posição por 2, pois a velocidade também foi multiplicada por 2.\n",
    "\n",
    "Por exemplo, se a função f(x) = x^2 representa a posição do objeto em relação ao tempo, sua derivada f'(x) = 2x representa a velocidade do objeto. Se multiplicarmos a função f(x) por 2, obtemos a função g(x) = 2x^2. A derivada de g(x) é dada por g'(x) = 4x, que é 2 vezes maior que f'(x). Isso ocorre porque, ao multiplicar f(x) por 2, estamos multiplicando cada valor de f'(x) por 2.\n",
    "\n",
    "<img src=\"./imgs/propertie_mult1.png\"> \n",
    "<img src=\"./imgs/propertie_mult2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c623c",
   "metadata": {},
   "source": [
    "## Properties of Derivative: The sum rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a84323",
   "metadata": {},
   "source": [
    "A regra da soma de derivadas é uma propriedade do cálculo diferencial que nos permite calcular a derivada de uma soma de funções. Essa regra afirma que, para duas funções $f(x)$ e $g(x)$, a derivada da sua soma $f(x) + g(x)$ é igual à soma das derivadas de cada função $f'(x) + g'(x)$.\n",
    "\n",
    "Matematicamente, podemos escrever a regra da soma de derivadas da seguinte forma:\n",
    "\n",
    "$(f(x) + g(x))' = f'(x) + g'(x)$\n",
    "\n",
    "Podemos entender essa regra de forma intuitiva pensando na derivada como a taxa de variação instantânea de uma função. Se estamos somando duas funções $f(x)$ e $g(x)$, a taxa de variação instantânea da soma é igual à soma das taxas de variação instantâneas de cada função individualmente.\n",
    "\n",
    "Por exemplo, suponha que temos as funções $f(x) = x^2$ e $g(x) = 3x$. Queremos encontrar a derivada da sua soma, $f(x) + g(x)$. Podemos aplicar a regra da soma de derivadas da seguinte forma:\n",
    "\n",
    "$$(f(x) + g(x))' = f'(x) + g'(x)$$\n",
    "\n",
    "Sabemos que a derivada de $f(x)$ é $f'(x) = 2x$, e a derivada de $g(x)$ é $g'(x) = 3$. Portanto, podemos substituir $f'(x)$ e g'(x) na equação acima para obter:\n",
    "\n",
    "$$(f(x) + g(x))' = 2x + 3$$\n",
    "\n",
    "Isso significa que a derivada da soma das funções $f(x)$ e $g(x)$ é igual a $2x + 3$. Essa é a taxa de variação instantânea da soma das funções $f(x)$ e $g(x)$ em qualquer ponto $x$.\n",
    "\n",
    "<img src=\"./imgs/propertie_sum_rule1.png\">\n",
    "<img src=\"./imgs/propertie_sum_rule2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f60a28",
   "metadata": {},
   "source": [
    "## Properties of Derivative: The product rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9735edac",
   "metadata": {},
   "source": [
    "A **product rule** é bem semelhante a **sum rule**, mas com um diferencial.\n",
    "\n",
    "$$ f = gh $$\n",
    "\n",
    "$$ f' = g'h + gh'$$\n",
    "\n",
    "<img src=\"./imgs/product_rule.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ab268",
   "metadata": {},
   "source": [
    "## Properties of Derivative: The chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9afaf",
   "metadata": {},
   "source": [
    "A regra da cadeia (chain rule, em inglês) é uma regra do cálculo que nos permite calcular a derivada de uma função composta (\"uma dentro da outra\"). Funções compostas são aquelas que consistem de uma função \"externa\" e uma função \"interna\" aplicada a ela. A regra da cadeia nos diz como as derivadas da função interna e externa se combinam para dar a derivada da função composta. **O resultado de uma função composta é o produto das derivadas internas**.\n",
    "\n",
    "De forma intuitiva, podemos pensar na regra da cadeia como um efeito dominó. Quando aplicamos uma função composta a um valor x, primeiro aplicamos a função interna ao valor x, obtendo um novo valor. Em seguida, aplicamos a função externa a esse novo valor, obtendo o resultado final da função composta.\n",
    "\n",
    "A regra da cadeia nos diz que, para calcular a derivada da função composta, precisamos **multiplicar (produto) a derivada da função interna pela derivada da função externa aplicada à função interna**. Ou seja, se f(x) é a função composta de u(v(x)), então a derivada de f(x) é dada por:\n",
    "\n",
    "$$\\frac{d}{dt}f(g(h(t))) = \\frac{df}{dg}\\cdot\\frac{dg}{dh}\\cdot\\frac{dh}{dt}$$\n",
    "\n",
    "<img src=\"./imgs/idea_chain_rule.png\">\n",
    "\n",
    "<img src=\"./imgs/chain_rule.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ae798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b447e8",
   "metadata": {},
   "source": [
    "## Meaning of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325eee4",
   "metadata": {},
   "source": [
    "Otimização é um ramo da matemática que lida com a **maximização ou minimização de uma função** em relação a suas variáveis. Em outras palavras, o objetivo da otimização é **encontrar a melhor solução possível** para um problema, geralmente sujeito a uma série de restrições.\n",
    "\n",
    "Em muitos casos, é possível usar a derivada de uma função para encontrar o mínimo ou máximo global dessa função. Esse processo é conhecido como otimização diferenciável. Quando uma função é diferenciável, podemos encontrar seus pontos críticos calculando a derivada da função e encontrando os pontos onde a derivada é igual a zero. Em seguida, podemos avaliar a função em cada um desses pontos críticos para determinar o mínimo ou máximo global.\n",
    "\n",
    "Em machine learning, a otimização é frequentemente usada para **ajustar os parâmetros de um modelo de aprendizado de máquina para minimizar o erro em um conjunto de dados de treinamento**. A otimização é realizada por meio de um algoritmo de otimização, que geralmente **usa a derivada da função de perda em relação aos parâmetros** do modelo para atualizar esses parâmetros em cada etapa do processo de treinamento.\n",
    "\n",
    "Um exemplo comum de algoritmo de otimização usado em machine learning é o gradiente descendente. O gradiente descendente é um algoritmo iterativo que usa a derivada da função de perda em relação aos parâmetros do modelo para atualizar esses parâmetros na direção do mínimo local da função de perda. O algoritmo continua a iterar até que a função de perda seja minimizada ou até que uma condição de parada seja atendida.\n",
    "\n",
    "Em resumo, a otimização é um importante conceito matemático que é amplamente utilizado em machine learning para ajustar os parâmetros de um modelo de aprendizado de máquina para minimizar o erro em um conjunto de dados de treinamento. A derivada é frequentemente usada para encontrar o mínimo ou máximo global de uma função, o que é útil para ajustar os parâmetros do modelo de forma eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e8a52",
   "metadata": {},
   "source": [
    "## Optimization of Squared Loss - Powerline Problem\n",
    "\n",
    "Esse problema consiste em mover a casa para o mais próximo possível da rede elétrica, para diminuir o custo de se ter energia, de se concetar à rede elétrica. Esse custo se dá pelo tamanho do cabeamento e quanto mais longe da rede, maior é o custo. Esse custo é similar ao **erro quadrado (squared error)**.\n",
    "\n",
    "Diante de um número X de powerlines, precisamos construir a casa no local com menor custo para acessar a rede elétrica, ou seja, menor squared error.\n",
    "\n",
    "<img src=\"./imgs/powerline_problem.png\">\n",
    "\n",
    "**The One Powerline:**\n",
    "\n",
    "Possuindo somente um ponto de distribuição, o menor custo, ou seja, o menor squared error é o local mais próximo do ponto de distribuição.\n",
    "\n",
    "<img src=\"./imgs/powerline_problem1.png\">\n",
    "\n",
    "**The Two Powerline**:\n",
    "\n",
    "Agora, possuindo dois pontos de distribuição, precisamos encontrar a localização que minimiza o custo considerando esses dois pontos, diminuindo o custo de se conectar em ambos. Ou seja, econtrar o x, a distância da casa até a origem, que minimize a função de custo $(x - a)^{2}+(x - b)^{2}$. **Precisamos encotrar o ponto em que a sua derivada é zero**\n",
    "\n",
    "<img src=\"./imgs/powerline_problem2.png\">\n",
    "<img src=\"./imgs/powerline_problem22.png\">\n",
    "\n",
    "**The Three Powerline:**\n",
    "Inserindo mais um ponto de distribuição, temos o mesmo problema mais com mais uma variável. Tendo o mesmo objetivo **minimizar o custo de se conectar com todos os pontos de distribuição**.\n",
    "\n",
    "<img src=\"./imgs/powerline_problem3.png\">\n",
    "<img src=\"./imgs/powerline_problem33.png\">\n",
    "<img src=\"./imgs/powerline_problem333.png\">\n",
    "\n",
    "**The Squared Loss:**\n",
    "Podemos generalizar a função de custo para n número de casas, ou, n número de variáveis. \n",
    "\n",
    "$$minimize(x - a1){2} + (x - a2){2} + ... + (x - an){2}$$ \n",
    "\n",
    "$$Solution: x = \\frac{a1 + a2 + ... + an}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ee83a",
   "metadata": {},
   "source": [
    "## Optmization of log-loss (rever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693607d5",
   "metadata": {},
   "source": [
    "A função de custo log-loss é uma medida comumente usada em problemas de classificação em machine learning. Ela é usada para medir o quão bem o modelo está prevendo as classes corretas para cada exemplo de treinamento.\n",
    "\n",
    "De forma intuitiva, a otimização da função de custo log-loss envolve a busca pelo conjunto de parâmetros do modelo que minimizam a diferença entre as classes reais e as classes previstas pelo modelo. Isso é feito encontrando o ponto mais baixo na curva da função de custo log-loss.\n",
    "\n",
    "Para entender melhor, imagine que estamos construindo um modelo de classificação binária para prever se um determinado e-mail é spam ou não. Para isso, usamos uma técnica de aprendizado supervisionado e treinamos nosso modelo com um conjunto de exemplos de e-mails rotulados como spam ou não spam.\n",
    "\n",
    "Ao avaliar nosso modelo, usamos a função de custo log-loss para medir o quão bem ele está prevendo as classes corretas para cada exemplo de treinamento. A função de custo log-loss é uma medida que penaliza o modelo quando ele faz previsões incorretas, dando maior peso para as previsões erradas.\n",
    "\n",
    "A otimização da função de custo log-loss envolve encontrar os parâmetros do modelo que minimizam essa penalidade global, ou seja, aqueles que fazem com que a função de custo log-loss atinja o ponto mais baixo possível. Isso é feito usando técnicas de otimização, como o gradiente descendente, que usam a derivada da função de custo log-loss em relação aos parâmetros do modelo para ajustar esses parâmetros em cada etapa do processo de treinamento.\n",
    "\n",
    "Em resumo, a otimização da função de custo log-loss envolve encontrar o conjunto de parâmetros do modelo que minimizam a diferença entre as classes reais e as classes previstas pelo modelo. Isso é feito usando técnicas de otimização que usam a derivada da função de custo log-loss em relação aos parâmetros do modelo para ajustar esses parâmetros e encontrar o ponto mais baixo da curva da função de custo log-loss.\n",
    "\n",
    "Suponha que estamos construindo um modelo de classificação de imagens que pode distinguir entre imagens de gatos e imagens de cachorros. Para treinar esse modelo, usamos um conjunto de dados rotulados com exemplos de imagens de gatos e cachorros.\n",
    "\n",
    "Depois de criar um modelo inicial, precisamos ajustar seus parâmetros para que ele seja capaz de prever corretamente se uma imagem é de um gato ou de um cachorro. Para fazer isso, usamos uma função de custo, como a log-loss, que mede o quão bem o modelo está fazendo essas previsões.\n",
    "\n",
    "A log-loss penaliza o modelo quando ele faz previsões incorretas, dando maior peso para as previsões erradas. Queremos minimizar a log-loss, ou seja, queremos que o modelo faça previsões cada vez melhores e mais precisas.\n",
    "\n",
    "Para ajustar os parâmetros do modelo e minimizar a log-loss, usamos uma técnica de otimização, como o gradiente descendente. O gradiente descendente usa a derivada da função de custo log-loss em relação aos parâmetros do modelo para ajustar esses parâmetros em cada etapa do processo de treinamento.\n",
    "\n",
    "Por exemplo, suponha que a log-loss atual do modelo seja 0,6 e queremos ajustar os parâmetros para reduzi-la. O gradiente descendente calcula a derivada da log-loss em relação aos parâmetros e, em seguida, ajusta os parâmetros em uma direção que reduz a log-loss.\n",
    "\n",
    "Isso é feito iterativamente até que o modelo atinja o ponto mais baixo da curva da log-loss, onde a log-loss é mínima e o modelo é capaz de fazer previsões muito precisas e confiáveis sobre se uma imagem é de um gato ou de um cachorro.\n",
    "\n",
    "Em resumo, a otimização da função de custo log-loss é usada para ajustar os parâmetros de um modelo de forma a minimizar a diferença entre as classes reais e as classes previstas pelo modelo. Isso é feito usando técnicas de otimização, como o gradiente descendente, que usam a derivada da função de custo log-loss em relação aos parâmetros do modelo para ajustar esses parâmetros e encontrar o ponto mais baixo da curva da função de custo log-loss.\n",
    "\n",
    "A função de custo log-loss é dada por:\n",
    "\n",
    "$$ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^m y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) $$\n",
    "\n",
    "onde $\\theta$ são os parâmetros do modelo, $m$ é o número de exemplos de treinamento, $y^{(i)}$ é a classe real do exemplo de treinamento $i$, $x^{(i)}$ é o vetor de features do exemplo de treinamento $i$, e $h_\\theta(x^{(i)})$ é a classe prevista pelo modelo para o exemplo de treinamento $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2981e2",
   "metadata": {},
   "source": [
    "# Week 2 - Gradients and Gradient Descendents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d497201",
   "metadata": {},
   "source": [
    "## Tangent Planes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86431a50",
   "metadata": {},
   "source": [
    "O Tangent Plane (plano tangente) é um conceito matemático que se refere a um plano que toca uma superfície em um determinado ponto, e tem a mesma inclinação da superfície nesse ponto. Em outras palavras, o Tangent Plane é o plano que melhor aproxima a superfície em um ponto específico, e é usado para descrever a geometria local da superfície nesse ponto.\n",
    "\n",
    "O Tangent Plane é usado em machine learning para realizar otimizações locais em funções de **várias variáveis** (até agora vimos somente com uma). Em muitos algoritmos de otimização, é necessário calcular a inclinação ou a derivada de uma função em um ponto específico, e o Tangent Plane pode ser usado para aproximar a função localmente em torno desse ponto.\n",
    "\n",
    "Por exemplo, em redes neurais, é comum usar o Tangent Plane para ajustar os pesos da rede durante o treinamento. A cada iteração, a inclinação da função de perda em relação aos pesos é calculada em um ponto específico, e o Tangent Plane é usado para aproximar a função localmente nesse ponto. Isso permite ajustar os pesos de forma a minimizar a função de perda em relação aos dados de treinamento.\n",
    "\n",
    "<img src=\"./imgs/tangent_plane1.png\">\n",
    "<img src=\"./imgs/tangent_plane2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9f157",
   "metadata": {},
   "source": [
    "## Partial Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1e558",
   "metadata": {},
   "source": [
    "Derivadas parciais são um conceito matemático usado para medir **como uma função muda em relação a uma de suas variáveis independentes, mantendo as outras variáveis constantes**. Em outras palavras, as derivadas parciais são as taxas de variação locais de uma função de várias variáveis em relação a cada uma de suas variáveis independentes, uma de cada vez.\n",
    "\n",
    "Por exemplo, considere uma função f(x,y) que representa a altura de uma montanha em diferentes pontos (x,y) no mapa. Para encontrar a inclinação da montanha em um ponto específico (x0,y0), podemos calcular as derivadas parciais de f em relação a x e y no ponto (x0,y0). A derivada parcial em relação a x nos dá a inclinação da montanha na direção x, mantendo y constante, enquanto a derivada parcial em relação a y nos dá a inclinação da montanha na direção y, mantendo x constante.\n",
    "\n",
    "As derivadas parciais são usadas em machine learning para ajustar os parâmetros de um modelo de forma a minimizar a função de perda em relação aos dados de treinamento. Isso é feito por meio de algoritmos de otimização, como o Gradiente Descendente, que usam as derivadas parciais da função de perda em relação a cada um dos parâmetros do modelo para atualizar seus valores em cada iteração.\n",
    "\n",
    "Por exemplo, considere uma rede neural que possui pesos (parâmetros) w1, w2, ..., wn. Durante o treinamento, a rede neural recebe um conjunto de dados de treinamento e tenta ajustar seus pesos para minimizar a função de perda em relação aos dados de treinamento. Para fazer isso, é necessário calcular a derivada parcial da função de perda em relação a cada um dos pesos.\n",
    "\n",
    "O Gradiente Descendente usa essas derivadas parciais para atualizar os valores dos pesos em cada iteração, de forma a minimizar a função de perda. A ideia é seguir na direção oposta ao gradiente da função de perda, pois essa direção corresponde à maior taxa de variação negativa da função. Dessa forma, os valores dos pesos são atualizados iterativamente até que a função de perda seja minimizada.\n",
    "\n",
    "As derivadas parciais também são usadas em outras áreas do machine learning, como regressão linear, análise discriminante e classificação de imagens, para citar alguns exemplos. Em geral, as derivadas parciais são usadas para medir a sensibilidade de uma função em relação a seus parâmetros, permitindo ajustá-los de forma a melhorar o desempenho do modelo.\n",
    "\n",
    "<img src=\"./imgs/derivada_parcial.png\">\n",
    "\n",
    "Podemos calcular a derivada parcial para cada variável em relação as demais, nesse caso, temos $x^{2} + y^{2}$. Tratando y como uma constante, a darivada parcial é 2x. Mas caso x seja tratado como uma constante, o resultado será 2y.\n",
    "\n",
    "$$f(x, y)$$\n",
    "\n",
    "Derivada parcial de f em relação ao x:\n",
    "$$fx = \\frac{df}{dx}$$\n",
    "\n",
    "Derivada parcial de f em relação ao y:\n",
    "$$fx = \\frac{df}{dy}$$\n",
    "\n",
    "Para chegarmos ao resultado precisamos seguir dois passos;\n",
    "1. Tratar as demais variáveis como constante.\n",
    "2. Seguir as regras de diferenciação (cálculo de derivada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd1944",
   "metadata": {},
   "source": [
    "## Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2e9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T22:36:19.576269Z",
     "start_time": "2023-03-20T22:36:19.573997Z"
    }
   },
   "source": [
    "**Um gradiente é um vetor que contêm as derivadas parciais**. $$f(x, y) = x^{2} + y^{2}$$\n",
    "\n",
    "O Gradiente de $f(x, y)$ é:\n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix} 2x \\\\ 2y \\end{bmatrix}$$\n",
    "\n",
    "<img src=\"./imgs/gradiente1.png\">\n",
    "\n",
    "O plano tangente (laranja) descreve a inclinação das duas linhas que formam o plano tangente. \n",
    "\n",
    "<img src=\"./imgs/gradiente2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3c7fd",
   "metadata": {},
   "source": [
    "## Gradients and Maxima/Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3d7f7",
   "metadata": {},
   "source": [
    "O gradiente é util pra minimizar funções com mais de uma variável, da mesma forma que a derivada é util para minimizar a função com uma variável.\n",
    "\n",
    "Para encontrar o minimums e o máximums precisamos encontrar os pontos das derivadas parciais, o gradiente, que minimizem o valor de ambos. Ou maximizem o valor de ambos. Pra isso, precisamos _settar_ as derivadas parciais para zero, e resolver o sistema de equações (nesse caso).\n",
    "\n",
    "<img src=\"./imgs/gradiente_minmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4663f7d",
   "metadata": {},
   "source": [
    "## Optimization with Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017341c",
   "metadata": {},
   "source": [
    "Numa sauna, a **pessoa A** deseja encontrar o ponto da sala em que faz menos calor. Como ela pode encotrar ? Através do gradiente descendente!\n",
    "\n",
    "Para cada pontonto xy, em que x e y são duas coordenadas, aqui, a temperatura é o **valor da função naquele ponto**, representado pela altura T(ºC). \n",
    "\n",
    "Aqui o objetivo é **encontrar o ponto mais frio ou menos quente da sala**, ou seja minimizar a função de custo em relação a temperatura. Precisamos chear ao ponto em que o gradiente que minimiza o valor das duas derivadas parciais, em relação a x e em relação a y. Encontrarmos, através do gradiente descendente, o ponto em que a inclinação é zero. Nesse ponto, o plano tangente é paralelo ao \"chão\". Aqui ponto, para qualquer direção que nos movermos nesta sala, a temperatura irá aumentar.\n",
    "\n",
    "<img src=\"./imgs/gradiente_sauna1.png\">\n",
    "\n",
    "Agora, verificando matemáticamente:\n",
    "\n",
    "- Primeiro, precisamos encotrar as derivadas parciais em relação a x e a y; Precisamos tratar y como uma constante para encontrar a derivada parcial em relação ao x, e depois o x como uma contante para encontrar a derivada parcial em relação ao y. \n",
    "- Depois, precisamos igualar ambos a zero, para contrar o ponto que minimiza a função; como o $\\frac{df}{dx}$ e $\\frac{df}{dy}$ é um produto de vários elementos e precisamos que o resultado seja zero, basta substituir uma das variáveis por zero para que o resultado das multiplicações seja zero, para que cheguemos ao resultado!\n",
    "\n",
    "<img src=\"./imgs/gradiente_sauna2.png\">\n",
    "\n",
    "Agora, basta verificarmos em que ponto no plano as coordenadas x e y minimizam a temperatura.\n",
    "\n",
    "<img src=\"./imgs/gradiente_sauna3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2361f",
   "metadata": {},
   "source": [
    "## Optimization with Gradients Using Analytical Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae5b28",
   "metadata": {},
   "source": [
    "Voltando àquele mesmo problema de rede elétrica, agora, precisamos encontrar o lugar ótimo para que a linha que se conecta aos pontos de distribuição tenha o menor custo. O objetivo é **minimizar a soma dos quadrados** (custo).\n",
    "\n",
    "<img src=\"./imgs/linear_reg1.png\">\n",
    "\n",
    "Para calcular a função que queremos minimizar, precisamos encontrar os pontos em que a linha da regressão se conecta aos pontos de distribuição. Por exemplo, o ponto azul, se conecta à linha no ponto $(1, m+b)$, porquê se $x = 1$, então $mx + b$ é igual a $m + b$. **O ponto em que se conecta ao ponto de distribuição é m+b, ou seja, 2**. Assim y = mx + b é o mesmo que $2 = 1 \\cdot 1 + 1$. Mas a distância é $(m+b -2)$ e o custo é $(m+b -2)^{2}$. E o mesmo segue para os outros dois pontos laranja e verde. Assim, chegamos nas três funções de custo.\n",
    "\n",
    "<img src=\"./imgs/linear_reg2.png\">\n",
    "\n",
    "Para minimizar a função de custo $E(m, b)$, precisamos encontrar as derivadas parciais em relação ao m e ao b, igualando ambos a zero e resolvendo para m e b.\n",
    "\n",
    "<img src=\"./imgs/linear_reg3.png\">\n",
    "\n",
    "Para resolvermos, precisamos usar álgebra linear para resolver esse **sistema de equações**.\n",
    "\n",
    "Para resolver a segunda equação, **multiplicamos os valores por 2**, subtraísmos a primeira equação por ela, chegando em $4m - 2 = 0$, depois chegamos a $m = \\frac{2}{4} = 0.5$. Com esse resultado de $m = 0.5$, colocamos o valor de m na segunda equação e resolvemos para encontrar o valor de b e resolver a primeira equação.\n",
    "\n",
    "<img src=\"./imgs/linear_reg4.png\">\n",
    "<img src=\"./imgs/linear_reg5.png\">\n",
    "\n",
    "**Esses dois valores de m e b, são os valores que fazem as duas derivadas parciais serem zero.**\n",
    "\n",
    "Agora, verificando no gráfico\n",
    "<img src=\"./imgs/linear_reg6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1d634",
   "metadata": {},
   "source": [
    "## Analytical Gradient is same Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19c475",
   "metadata": {},
   "source": [
    "**Não**, gradiente analítico e regressão linear são conceitos diferentes, embora possam estar relacionados em certos contextos.\n",
    "\n",
    "Gradiente analítico é um método de otimização usado para encontrar os parâmetros ideais de um modelo de aprendizado de máquina. Esse método envolve calcular o gradiente da função de custo (também conhecida como função objetivo) em relação aos parâmetros do modelo e, em seguida, atualizar iterativamente esses parâmetros na direção oposta do gradiente, com o objetivo de minimizar a função de custo.\n",
    "\n",
    "Por outro lado, regressão linear é um tipo de modelo de aprendizado de máquina que visa modelar a relação entre uma variável dependente (ou variável de resposta) e uma ou mais variáveis independentes (ou variáveis preditoras) usando uma função linear. A regressão linear pode ser usada para fins de previsão ou para entender a relação entre as variáveis.\n",
    "\n",
    "Embora o gradiente analítico possa ser usado para encontrar os parâmetros ideais de um modelo de regressão linear, ele também pode ser usado para otimizar outros tipos de modelos de aprendizado de máquina, como redes neurais. Portanto, embora os dois conceitos possam estar relacionados em certos contextos, eles não são a mesma coisa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea97c1c",
   "metadata": {},
   "source": [
    "## Optimization Using Gradient Descendent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642cf4e6",
   "metadata": {},
   "source": [
    "O **gradiente descendente** é um algoritmo de otimização usado para encontrar o mínimo local de uma função diferenciável. A ideia principal por trás do gradiente descendente é ajustar os parâmetros de um modelo **iterativamente**, de forma que a função de perda associada ao modelo seja minimizada.\n",
    "\n",
    "A vantagem do gradiente descendente em relação ao gradiente analítico é que **ele pode ser usado para otimizar funções** não lineares e não convexas, para as quais **não existe uma solução analítica simples**. Além disso, o gradiente descendente pode ser usado para minimizar funções de perda **que envolvam grandes conjuntos de dados**, onde a computação do gradiente analítico pode ser proibitivamente cara.\n",
    "\n",
    "Em machine learning, o gradiente descendente é frequentemente usado para ajustar os parâmetros de um modelo de aprendizado de máquina. Por exemplo, em redes neurais, o gradiente descendente é usado para ajustar os pesos sinápticos de forma que a rede neural possa aprender a função de mapeamento desejada. \n",
    "\n",
    "Ele é amplamente utilizado para ajustar os parâmetros de um modelo de regressão linear. O objetivo da regressão linear é encontrar uma linha reta que melhor se ajusta aos dados de treinamento, ou seja, minimizar a diferença entre os valores previstos e os valores observados.\n",
    "\n",
    "O processo de otimização do gradiente descendente começa com a definição de uma função de perda, que mede a diferença entre os valores previstos pelo modelo e os valores observados nos dados de treinamento. Para a regressão linear, a função de perda mais comum é a soma dos erros quadrados (SSE), que é dada pela fórmula:\n",
    "\n",
    "SSE = 1/2m * somatório(i=1 até m) [(y_i - y_pred_i)^2]\n",
    "\n",
    "onde y_i é o valor observado na i-ésima amostra, y_pred_i é o valor previsto pelo modelo, m é o número total de amostras.\n",
    "\n",
    "O objetivo do gradiente descendente é ajustar os parâmetros do modelo, como o intercepto e os coeficientes de inclinação, de forma a minimizar a função de perda SSE. Para fazer isso, o algoritmo calcula o gradiente da função SSE em relação aos parâmetros do modelo. Em seguida, ele atualiza os valores dos parâmetros na direção oposta ao gradiente, com uma taxa de aprendizado que controla o tamanho do passo. Os parâmetros são ajustados na direção oposta ao gradiente para minimizar a função de perda associada ao modelo. O gradiente de uma função de perda indica a direção de maior crescimento da função, ou seja, a direção em que a função aumenta mais rapidamente.\n",
    "\n",
    "A atualização dos parâmetros é feita em cada iteração do algoritmo, de acordo com a seguinte fórmula:\n",
    "\n",
    "theta_j = theta_j - alpha * (1/m) * somatório(i=1 até m) [(h_theta(x_i) - y_i) * x_ij]\n",
    "\n",
    "onde theta_j é o valor atual do j-ésimo parâmetro (intercepto ou coeficiente de inclinação), alpha é a taxa de aprendizado, h_theta(x_i) é a hipótese do modelo para a i-ésima amostra e x_ij é o valor do j-ésimo atributo na i-ésima amostra.\n",
    "\n",
    "O processo de atualização dos parâmetros é repetido até que a função de perda SSE seja minimizada ou até que um critério de parada seja atingido. O resultado final é um modelo de regressão linear que melhor se ajusta aos dados de treinamento, com parâmetros que minimizam a função de perda SSE.\n",
    "\n",
    "O algoritmo de gradiente descendente é implementado em um **processo iterativo** que envolve a **computação do gradiente da função de perda em relação aos parâmetros do modelo**, e então **ajusta os parâmetros na direção oposta ao gradiente** até que a função de perda seja minimizada. Existem diferentes variantes do gradiente descendente, como o estocástico, o mini-batch, o momentum e o AdaGrad, que são adaptados para diferentes tipos de problemas de otimização e modelos de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62851747",
   "metadata": {},
   "source": [
    "O **learning rate**, ou taxa de aprendizado, é um hiperparâmetro que controla a magnitude da atualização dos parâmetros em relação ao gradiente. Em outras palavras, **o learning rate determina o tamanho do passo** que o algoritmo de otimização deve dar em direção ao mínimo da função de perda em cada iteração.\n",
    "\n",
    "Na regra de atualização do gradiente descendente, **o learning rate é multiplicado pelo gradiente da função de perda em relação aos parâmetros**, a fim de determinar a magnitude da atualização dos parâmetros em cada iteração. Se o learning rate for muito grande, a atualização dos parâmetros será muito grande e o algoritmo pode não convergir para a solução correta, pois pode saltar sobre o mínimo da função de perda. Se o learning rate for muito pequeno, a atualização dos parâmetros será muito pequena e o algoritmo pode convergir muito lentamente para a solução correta.\n",
    "\n",
    "Portanto, escolher a taxa de aprendizado adequada é essencial para o sucesso do algoritmo de otimização. Em geral, é recomendado começar com uma taxa de aprendizado pequena e aumentá-la gradualmente, observando o desempenho do modelo em um conjunto de validação. Também existem técnicas de otimização adaptativa que ajustam automaticamente a taxa de aprendizado com base no histórico das atualizações dos parâmetros.\n",
    "\n",
    "Em resumo, o learning rate controla a magnitude da atualização dos parâmetros em relação ao gradiente, e escolher a taxa de aprendizado adequada é um desafio importante na otimização de modelos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404ad56",
   "metadata": {},
   "source": [
    "**O algoritmo do gradient descendent**\n",
    "\n",
    "Function: $f(x)$\n",
    "Goal: Minimizar a função $f(x)$\n",
    "\n",
    "Passo 1:\n",
    "Definir o learninig rate $\\alpha$\n",
    "Escolher o ponto de partida $x_0$\n",
    "\n",
    "Passo 2:\n",
    "Atualizar\n",
    "$$ x_k = x_{k-1} \\alpha f'(x_{k-1})$$\n",
    "\n",
    "Passo 3:\n",
    "Repetir o passo 2 até que se chegue o mais próximo possível do mínimo verdadeiro. Ou, por um número **pré-determinado de iterações**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ffa38",
   "metadata": {},
   "source": [
    "## Optimization Using Gradient Descendent in Two Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c78a2d",
   "metadata": {},
   "source": [
    "Quando temos duas ou mais variáveis em um problema de aprendizado de máquina, usamos a regressão linear multivariada para estimar a relação entre as variáveis de entrada e a variável de saída. Nesse caso, a função de custo associada ao modelo de regressão linear é uma função de vários parâmetros, um para cada variável de entrada.\n",
    "\n",
    "Para atualizar os parâmetros em um modelo de regressão linear multivariada usando o gradiente descendente, precisamos **calcular o gradiente da função de custo em relação a cada um dos parâmetros**. O gradiente é uma matriz que contém as derivadas parciais da função de custo em relação a cada um dos parâmetros.\n",
    "\n",
    "A regra de atualização do gradiente descendente para a regressão linear multivariada é semelhante à regra para a regressão linear simples, exceto que **agora precisamos atualizar todos os parâmetros ao mesmo tempo**. A fórmula para a atualização dos parâmetros é:\n",
    "\n",
    "theta_j = theta_j - alpha * (1/m) * somatório(i=1 até m) [(h_theta(x_i) - y_i) * x_ij]\n",
    "\n",
    "onde theta_j é o j-ésimo parâmetro, alpha é a taxa de aprendizado, m é o número de exemplos de treinamento, h_theta(x_i) é a previsão do modelo para o i-ésimo exemplo de treinamento e y_i é o valor de saída verdadeiro para o i-ésimo exemplo de treinamento.\n",
    "\n",
    "A diferença é que agora x_ij é o valor da j-ésima variável de entrada para o i-ésimo exemplo de treinamento. Portanto, precisamos calcular a previsão do modelo h_theta(x_i) usando todos os parâmetros, não apenas um.\n",
    "\n",
    "Em resumo, para atualizar os parâmetros em um modelo de regressão linear multivariada usando o gradiente descendente, precisamos calcular o gradiente da função de custo em relação a cada um dos parâmetros e atualizar todos os parâmetros simultaneamente usando a regra de atualização do gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5d147",
   "metadata": {},
   "source": [
    "Neste mesmo exemplo da sauna, para encontrar o ponto menos quente utlizando o gradiente descendente para atualizar os parâmetros, como temos 2 variáveis, o x e o y, ambos são atualizados **simultaniamente** na direção oposta do gradiente, na direção oposta porquê o objetivo é **minimizar** a temperatura encontrando o lugar menos quente.\n",
    "\n",
    "<img src=\"./imgs/gradiente_sauna4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56069d5",
   "metadata": {},
   "source": [
    "**O algoritmo do gradient descendent** quando temos mais de uma variável é praticamente o mesmo.\n",
    "\n",
    "Function: $f(x, y)$\n",
    "Goal: Minimizar a função $f(x, y)$\n",
    "\n",
    "Passo 1:\n",
    "Definir o learninig rate $\\alpha$\n",
    "Escolher o ponto de partida $(x_0, y_0)$\n",
    "\n",
    "Passo 2:\n",
    "Atualizar\n",
    "$$  \\begin{bmatrix} x_k \\\\ y_k \\end{bmatrix} = \\begin{bmatrix} x_{k-1} \\\\ y_{k-1} \\end{bmatrix} - \\alpha \\nabla f(x_{k-1}, y_{k-1}) $$\n",
    "\n",
    "Passo 3:\n",
    "Repetir o passo 2 até que se chegue o mais próximo possível do mínimo verdadeiro. Ou, por um número **pré-determinado de iterações**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c0905",
   "metadata": {},
   "source": [
    "## Drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a3d34",
   "metadata": {},
   "source": [
    "Podemos encontra um ponto mínimo mas ele não ser o mínimo global. Uma das formas de evitar isso é iniciar em vários pontos diferentes, para buscar o \"menor mínimo\" ao longo do plano, ou seja, o **mínimo global**.\n",
    "\n",
    "<img src=\"./imgs/drawback_gradiente.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13ad32",
   "metadata": {},
   "source": [
    "## Optimization Using Gradient Descendent - Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454dd3d3",
   "metadata": {},
   "source": [
    "Retornando àquele exemplo da linha de transmissão de energia, mas agora, resolvendo a regressão linear utilizando o gradiente descendente.\n",
    "\n",
    "Para resolver usando o gradiente descendente precisamos seguir os seguintes passos:\n",
    "- Começar num ponto $(m_0, b_0)$\n",
    "- Iterar várias vezes até encontrar o ponto em que minimiza a função de custo\n",
    "$$  \\begin{bmatrix} m_k \\\\ b_k \\end{bmatrix} = \\begin{bmatrix} m_{k-1} \\\\ b_{k-1} \\end{bmatrix} - \\alpha \\nabla E(m_{k-1}, b_{k-1}) $$\n",
    "\n",
    "<img src=\"./imgs/reg_linear_gradiente.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9856a23",
   "metadata": {},
   "source": [
    "## Optimization Using Gradient Descendent - Least Square with Multiple Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7721216",
   "metadata": {},
   "source": [
    "O gráfico a direita representa o **custo** para se conectar aos pontos de transmissão. Em seu eixo vertical L está sendo mensurado o custo (loss), e nos eixos b e m, a variação dos pontos m e b da equação linear $y = mx + b$. Ao alterar os m e b, alteramos a posição da reta, assim como o custo em relação a reta da regressão. Esse custo pode ser visualizado pelo gráfico à direita.\n",
    "\n",
    "A soma dos quadrados são __plotados__ como a altura do custo, de acordo com a posição da reta da regressão. \n",
    "\n",
    "Usando o gradiente descendente, conseguimos encontrar a posição da reta da regressão em que o custo seja menor, ou seja, em que a altura dele seja menor no gráfico à direita. Através dos passos já mencionados.\n",
    "\n",
    "<img src=\"./imgs/reg_linear_gradiente2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c71f05",
   "metadata": {},
   "source": [
    "No algoritmo gradiente descendente, **não precisamos resolver explicitamente a derivada de uma função para minimizá-la**. Em vez disso, **utilizamos a informação da derivada para ajustar os valores dos parâmetros** da função iterativamente.\n",
    "\n",
    "O algoritmo gradiente descendente é um método iterativo que atualiza os valores dos parâmetros da função com base na direção e magnitude do gradiente da função. O gradiente é um vetor que aponta na direção de maior crescimento da função e sua magnitude indica a taxa de crescimento. O algoritmo gradiente descendente, por sua vez, atualiza os parâmetros da função na direção oposta do gradiente, de forma que a função é minimizada em cada iteração.\n",
    "\n",
    "Ao atualizar os parâmetros com base no gradiente, não precisamos calcular explicitamente a derivada da função. Em vez disso, podemos usar técnicas de aproximação, como a diferença finita ou a regressão linear, para estimar a derivada da função em cada ponto. Essas técnicas são computacionalmente mais eficientes do que o cálculo exato da derivada, que pode ser computacionalmente caro ou mesmo impossível para funções complexas ou que não possuem uma expressão analítica fechada.\n",
    "\n",
    "Em resumo, o algoritmo gradiente descendente usa o gradiente da função para ajustar iterativamente os valores dos parâmetros da função, sem a necessidade de resolver explicitamente a derivada da função. Isso torna o algoritmo mais eficiente e escalável para problemas de otimização de grande escala."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6e66d",
   "metadata": {},
   "source": [
    "# Week 3 - Optimization in Neural Networks and Newton's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6924d5",
   "metadata": {},
   "source": [
    "## Regression with a Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3466c",
   "metadata": {},
   "source": [
    "Um **perceptron** é um algoritmo de aprendizado supervisionado para classificação binária de dados. É um modelo de rede neural artificial de uma única camada, composto por um conjunto de nós de entrada, pesos e um nó de saída.\n",
    "\n",
    "O perceptron recebe uma série de entradas e produz uma única saída, que é uma predição binária (0 ou 1) para a classe do dado de entrada. Ele aprende ajustando os pesos associados a cada entrada, com base no erro de predição, usando um algoritmo de otimização como o Gradiente Descendente.\n",
    "\n",
    "O modelo foi proposto por Frank Rosenblatt em 1958, e seu objetivo era imitar o comportamento do cérebro humano, em particular a forma como os neurônios trabalham em conjunto para formar uma rede de processamento de informações. O perceptron é considerado o modelo mais simples de rede neural e serviu como base para o desenvolvimento de modelos de redes neurais mais complexos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1694c819",
   "metadata": {},
   "source": [
    "Uma **regressão linear** pode ser representada como um perceptron. No exemplo a seguir, tentaremos prever o preço de uma casa dado seu tamanho.\n",
    "\n",
    "<img src=\"./imgs/house1.png\">\n",
    "\n",
    "Para prever o preço da casa usando um **perceptron**, vamos adicionar mais uma feature, o número de quartos.\n",
    "\n",
    "<img src=\"./imgs/house2.png\">\n",
    "\n",
    "Expressando matematicamente o percetron:\n",
    "- Cada feature é multiplicada por um peso. Esse peso determina o quão importante a feature é para o resultado da predição.\n",
    "- Somamos um viés\n",
    "- seu resultado\n",
    "\n",
    "Aqui, o objetivo é achar o valor dos pesos e do viés que otimize a predição. Para otimizar a predição, precisamos **minimizar os erros da predição**.\n",
    "\n",
    "(Nesse modelo não temos função de ativação, que será nos próximos tópicos)\n",
    "\n",
    "<img src=\"./imgs/perceptron1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65810",
   "metadata": {},
   "source": [
    "## Regression with a Perceptron - Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0138e9",
   "metadata": {},
   "source": [
    "A função de perda \"mean squared error\" (MSE), ou erro quadrático médio em português, é uma medida comum usada para avaliar o desempenho de um modelo de aprendizado de máquina em tarefas de regressão.\n",
    "\n",
    "O MSE mede a média da diferença ao quadrado entre as previsões do modelo e os valores verdadeiros (ou rótulos) dos dados de treinamento. Quanto menor o valor do MSE, melhor é o desempenho do modelo em fazer previsões precisas.\n",
    "\n",
    "Matematicamente, o MSE é calculado pela seguinte fórmula:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} * \\sum_{i=1}^{n} (y_1 - \\hat{y})^{2} $$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $n$ é o número de exemplos no conjunto de treinamento\n",
    "- $y_1$ é o valor verdadeiro (rótulo) para o i-ésimo exemplo\n",
    "- $\\hat{y}$ é a média de todos os valores verdadeiros no conjunto de treinamento\n",
    "- $\\sum$ é o somatório de todos os exemplos no conjunto de treinamento\n",
    "\n",
    "Em Machine Learning, é comum **multiplicar o MSE por 1/2**, e isso é feito para **facilitar o cálculo da derivada da função de perda em relação aos pesos do modelo**.\n",
    "\n",
    "Para o nosso **perceptron**, sua loss function será\n",
    "\n",
    "$$ L(y, \\hat{y}) = \\frac{1}{2}(y - \\hat{y})^{2}$$\n",
    "\n",
    "Ou seja, o MSE. E o **objetivo** será encontrar os pelos $w1$, $w2$ e o viés $b$ que nos traga o valor predito $\\hat{y}$ com menor error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9948ed5",
   "metadata": {},
   "source": [
    "## Regression with a Perceptron - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db6261",
   "metadata": {},
   "source": [
    "Aplicando o **gadient descent** podemos encontrar os valores de $w1$, $w2$ e $b$ que minimizem o erro, para isso precisamos encontrar as derivadas parciais. Note que, o gradiente descent vai iterar os valores $w1$, $w2$ e $b$ para encontrar o menor erro, subtraindo o learning rate $\\alpha$ e a derivada em relação a variável.\n",
    "\n",
    "$$ w1 \\rightarrow w1 - \\alpha \\frac{\\partial L}{\\partial W_1} $$\n",
    "\n",
    "$$ w2 \\rightarrow w2 - \\alpha \\frac{\\partial L}{\\partial W_2} $$\n",
    "\n",
    "$$ b \\rightarrow b - \\alpha \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "Para calcular essas derivadas precisamos usar a **chain rule**:\n",
    "\n",
    "Relembrando nossa função de predição:\n",
    "$$ \\hat{y} = w1x1 + w2x2 + b$$\n",
    "\n",
    "Usando a chain rule:\n",
    "$$\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial b}$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w1} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial w1}$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial w2}$$\n",
    "\n",
    "Agora \"só\" precisamos calcular as 4 derivadas parciais (dL/dŷ repete 3x).\n",
    "\n",
    "Relembrando nossa função de perda:\n",
    "$$ L(y, \\hat(y) = \\frac{1}{2}(y - \\hat{y})^{2}$$\n",
    "\n",
    "<img src=\"./imgs/perceptron_gradient.png\">\n",
    "\n",
    "Retornando ao nosso problema, basta usarmos o resultado para atualizar os valores para encontrar os pesos e viés.\n",
    "\n",
    "<img src=\"./imgs/perceptron_gradient_step.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7027bd8",
   "metadata": {},
   "source": [
    "## Classification with Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6b55b",
   "metadata": {},
   "source": [
    "Ao alterar a função de ativação, para sigmoid, podemos utilizar o perceptron em problemas de classificação binária.\n",
    "\n",
    "Nesse exemplo de classificação binária de sentimento, assim como o exemplo de regressão, inputamos os valores de x1 e x2, predizemos um valor, no caso o sentimento, e, o modelo (reta da regressão) é feita a partir da nova função de ativação em vermelho.\n",
    "\n",
    "<img src=\"./imgs/perceptron_class.png\">\n",
    "\n",
    "Aqui, no nó interno, temos a diferença de que teremos a função de ativação sigmoide. resumidamente, ela transforma o valor da soma em um intervalo entre zero e um.\n",
    "\n",
    "<img src=\"./imgs/sigmoid_function.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387d1c0",
   "metadata": {},
   "source": [
    "## Classification with Perceptron - Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94157d4f",
   "metadata": {},
   "source": [
    "A função sigmoide é uma função matemática que é amplamente utilizada em análises de dados e aprendizado de máquina. Ela é uma função contínua, diferenciável e monótona crescente que mapeia um número real em um intervalo entre 0 e 1. Matematicamente, a função sigmoide é definida como:\n",
    "\n",
    "$$ f(x) = \\frac{1}{1 + e^{(-x)}} $$\n",
    "\n",
    "ou \n",
    "\n",
    "$$\\sigma (z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "podendo ser reescrita como\n",
    "\n",
    "$$ \\sigma (z) = (1 + e^{-z})^{-1}$$\n",
    "\n",
    "\n",
    "onde x/z é a entrada da função.\n",
    "\n",
    "A função sigmoide é assim chamada porque sua forma gráfica se assemelha a um \"S\" ou a letra grega sigma ($\\sigma$). A função é simétrica em relação ao ponto (0, 0.5), o que significa que a saída da função para entradas negativas é espelhada em relação à saída para entradas positivas.\n",
    "\n",
    "A função sigmoide é frequentemente usada para modelar a probabilidade de um evento binário ocorrer em função de uma variável contínua. Por exemplo, ela pode ser usada para prever a probabilidade de um cliente comprar um produto em função de seu histórico de compras ou para prever a probabilidade de um paciente ter uma determinada doença em função de seus sintomas.\n",
    "\n",
    "A função sigmoide tem algumas propriedades interessantes, como:\n",
    "\n",
    "Ela é diferenciável em todos os pontos, o que a torna adequada para o cálculo de gradientes em algoritmos de aprendizado de máquina.\n",
    "Ela mapeia números infinitos positivos e negativos em um intervalo finito entre 0 e 1, o que é útil para normalizar os dados e garantir que todas as entradas estejam na mesma escala.\n",
    "Ela é monótona crescente, o que significa que a saída da função aumenta à medida que a entrada aumenta, o que é útil para modelar relações positivas entre variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f954f8e",
   "metadata": {},
   "source": [
    "## Classification with Perceptron - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786923dd",
   "metadata": {},
   "source": [
    "A função sigmoide é usada em conjunto com o algoritmo de otimização do gradiente descendente para ajustar os parâmetros de um modelo de aprendizado de máquina. O objetivo do gradiente descendente é minimizar uma função de perda, que mede o quão bem o modelo se ajusta aos dados observados.\n",
    "\n",
    "Durante a fase de treinamento do modelo, o gradiente descendente calcula o gradiente da função de perda em relação aos parâmetros do modelo e usa essa informação para atualizar os parâmetros em direção à direção oposta ao gradiente. Isso é feito iterativamente até que a função de perda seja minimizada ou um critério de parada seja atingido.\n",
    "\n",
    "A função sigmoide é usada para transformar a saída do modelo em uma probabilidade, que é usada para calcular a função de perda. Em seguida, o gradiente da função de perda em relação aos parâmetros é calculado usando a regra da cadeia e a derivada da função sigmoide em relação à sua entrada.\n",
    "\n",
    "A derivada da função sigmoide é dada por:\n",
    "\n",
    "$$ f'(x) = f(x) * (1 - f(x)) $$\n",
    "\n",
    "ou\n",
    "\n",
    "$$\\frac{d}{dz} \\sigma (z) = \\sigma (z) (1 - \\sigma (z))$$\n",
    "\n",
    "Essa é uma expressão simples que pode ser facilmente calculada para qualquer entrada x.\n",
    "\n",
    "Durante a fase de treinamento, o gradiente descendente calcula o gradiente da função de perda em relação aos parâmetros do modelo usando a regra da cadeia e a derivada da função sigmoide. Em seguida, os parâmetros do modelo são atualizados em direção oposta ao gradiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ba63a",
   "metadata": {},
   "source": [
    "Log loss, também conhecido como entropia cruzada binária, é uma função de perda usada para avaliar o desempenho de modelos de classificação binária. A log loss mede a diferença entre as probabilidades preditas pelo modelo e as probabilidades reais dos dados de treinamento.\n",
    "\n",
    "A log loss é definida como:\n",
    "\n",
    "$$ L(y, y') = - (y * log(y') + (1 - y) * log(1 - y')) $$\n",
    "\n",
    "Onde y é a classe verdadeira (0 ou 1) e y' é a probabilidade predita pelo modelo de que a classe é 1.\n",
    "\n",
    "A log loss é uma função contínua e diferenciável, o que a torna adequada para o uso com o algoritmo de otimização do gradiente descendente. O objetivo do gradiente descendente é minimizar a log loss ajustando os pesos do modelo de modo que as probabilidades preditas sejam o mais próximas possível das probabilidades reais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef03e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T21:46:33.350375Z",
     "start_time": "2023-03-28T21:46:33.348003Z"
    }
   },
   "source": [
    "<img src=\"./imgs/perceptron_partial.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b413215",
   "metadata": {},
   "source": [
    "A ideia por trás do gradiente descendente é ajustar os pesos e bias do modelo de tal forma que a função de perda seja minimizada. No caso da log loss, o objetivo é minimizar a diferença entre as probabilidades preditas e as probabilidades reais.\n",
    "\n",
    "O processo de atualização dos pesos e bias pode ser resumido em três etapas:\n",
    "- **Cálculo do gradiente da função de perda em relação aos pesos e bias**. Esse cálculo é realizado usando a regra da cadeia para calcular as **derivadas parciais da função de perda em relação aos pesos e bias**.\n",
    "\n",
    "- **Atualização dos pesos e bias** usando a direção do gradiente e uma taxa de aprendizado. A taxa de aprendizado determina a quantidade de mudança que é feita em cada atualização. Um valor muito baixo pode resultar em uma convergência lenta, enquanto um valor muito alto pode resultar em oscilações em torno do mínimo global.\n",
    "\n",
    "- Repetição dos passos 1 e 2 até que a função de perda seja minimizada ou um número máximo de iterações seja alcançado.\n",
    "\n",
    "Mais especificamente, a atualização dos pesos e bias usando a log loss pode ser resumida nas seguintes equações:\n",
    "\n",
    "Para um único exemplo de treinamento:\n",
    "\n",
    "- Para cada peso w_j:\n",
    "$$w_j = w_j - \\alpha * (y' - y) * x_j$$\n",
    "\n",
    "onde y é a classe verdadeira (0 ou 1), y' é a probabilidade predita pelo modelo de que a classe é 1, x_j é o valor da j-ésima feature e taxa de aprendizado é um hiperparâmetro escolhido previamente.\n",
    "\n",
    "- Para o bias b:\n",
    "$$ b = b - \\alpha * (y' - y)$$\n",
    "\n",
    "onde y é a classe verdadeira (0 ou 1) e y' é a probabilidade predita pelo modelo de que a classe é 1.\n",
    "\n",
    "Para o conjunto inteiro de exemplos de treinamento, o processo de atualização dos pesos e bias é **repetido várias vezes** até que a função de perda seja minimizada ou um **número máximo de iterações seja alcançado**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96601a18",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/perceptron_gradient_descent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3698a26",
   "metadata": {},
   "source": [
    "## Classification with a Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e6ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2906b52",
   "metadata": {},
   "source": [
    "## Classification with a Neural Network - Minimizing log-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad644b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b10445",
   "metadata": {},
   "source": [
    "## Gradient Descent and Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ecefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2865d63",
   "metadata": {},
   "source": [
    "## Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34066f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fd6c9d7",
   "metadata": {},
   "source": [
    "## The second derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5179ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab808878",
   "metadata": {},
   "source": [
    "## The Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d607d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e7f3c22",
   "metadata": {},
   "source": [
    "## Hessian and concavity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0dfb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dd6c3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T21:00:40.265761Z",
     "start_time": "2023-03-27T21:00:40.263742Z"
    }
   },
   "source": [
    "## Newton's Method for two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3807c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa4261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef349bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ababf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91932c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937d1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b53d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4b2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd2f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d40b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4937884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c51f2115",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.465px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
